{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DISTRIBUTED (Data Parallel) Multi-Class Classification with `Trainer` and `OIG-moderation` dataset\n",
    "## Based on Huggingface Sagemaker-sdk - Getting Started Demo\n",
    "#### Ed Lee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Introduction](#Introduction)  \n",
    "2. [Development Environment and Permissions](#Development-Environment-and-Permissions)\n",
    "    1. [Installation](#Installation)  \n",
    "    2. [Development environment](#Development-environment)  \n",
    "    3. [Permissions](#Permissions)\n",
    "3. [Processing](#Preprocessing)   \n",
    "    1. [Tokenization](#Tokenization)  \n",
    "    2. [Uploading data to sagemaker_session_bucket](#Uploading-data-to-sagemaker_session_bucket)  \n",
    "4. [Fine-tuning & starting Sagemaker Training Job](#Fine-tuning-\\&-starting-Sagemaker-Training-Job)  \n",
    "    1. [Creating an Estimator and start a training job](#Creating-an-Estimator-and-start-a-training-job)  \n",
    "    2. [Estimator Parameters](#Estimator-Parameters)   \n",
    "    3. [Download fine-tuned model from s3](#Download-fine-tuned-model-from-s3)\n",
    "    4. [Attach to old training job to an estimator ](#Attach-to-old-training-job-to-an-estimator)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Welcome to our end-to-end Multi-Class Text-Classification example. In this demo, we will use the Hugging Faces `transformers` and `datasets` library together with a custom Amazon sagemaker-sdk extension to fine-tune a pre-trained transformer on muti-class text classification. In particular, the pre-trained model will be fine-tuned using the `OIG-moderation` dataset. To get started, we need to set up the environment with a few prerequisite steps, for permissions, configurations, and so on. \n",
    "\n",
    "_**NOTE: You can run this demo in Sagemaker Studio, your local machine or Sagemaker Notebook Instances**_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development Environment and Permissions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Installation\n",
    "\n",
    "_*Note:* we only install the required libraries from Hugging Face and AWS. You also need PyTorch or Tensorflow, if you haven´t it installed_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install \"sagemaker>=2.140.0\" \"transformers==4.26.1\" \"datasets[s3]==2.10.1\" \"ipywidgets\" --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Development environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker.huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_If you are going to use Sagemaker in a local environment. You need access to an IAM Role with the required permissions for Sagemaker. You can find [here](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html) more about it._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Permissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Must Login to Hugging Face Hub  to Download OIG-moderation\n",
    "Please create an API key in Settings -> Access Tokens and enter when prompted below.\n",
    "\n",
    "If below does not render in notebook, use a terminal and run a python3 consolde and use `from huggingface_hub import login`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d612932456bf4122b11d7171a8af9b9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "We are using the `datasets` library to download and preprocess the `OIG-moderation` dataset. After preprocessing, the dataset will be uploaded to our `sagemaker_session_bucket` to be used within our training job. \n",
    "\n",
    "https://huggingface.co/datasets/ontocord/OIG-moderation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset \n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "# tokenizer used in preprocessing\n",
    "tokenizer_name = 'distilbert-base-uncased'\n",
    "\n",
    "# dataset used\n",
    "dataset_name = 'ontocord/OIG-moderation'\n",
    "\n",
    "# s3 key prefix for the data\n",
    "s3_prefix = 'samples/datasets/OIG-moderation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset json (/root/.cache/huggingface/datasets/ontocord___json/ontocord--OIG-moderation-0dac4560d8f6e324/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10257c8dad2245f0ba5b3ee167cde045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# If the dataset is gated/private, make sure you have run huggingface-cli login\n",
    "\n",
    "loaded_dataset = load_dataset(dataset_name) # smaller the size for dataset to 10k for faster iterating\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Cleaning for the OIG-moderation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample down for faster iteration, ok for illustrative purposes.\n",
    "SAMPLE_SIZE = 20000\n",
    "CLASS_LABEL_COL = 'str_labels'\n",
    "\n",
    "# Need to clean up loaded dataset\n",
    "orig_df = pd.DataFrame(loaded_dataset).sample(n=SAMPLE_SIZE, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93943e96b29d490d8c8c881b1204cf8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/16060 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d915f1f7eee43649b75772160e3fd06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16060 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_parsed_df(orig_df):\n",
    "    parsed_df = orig_df.copy()\n",
    "    parsed_df['old_text'] = parsed_df['train'].apply(lambda x: x.get(\"text\"))\n",
    "    split_text = parsed_df['old_text'].str.split('\\n')\n",
    "    parsed_df['text'] = split_text.str[0].str.split(':').str[1].str.strip()\n",
    "    parsed_df[CLASS_LABEL_COL] = split_text.str[1].str.split(':').str[1].str.strip()\n",
    "    return parsed_df\n",
    "\n",
    "def get_cleaned_labels_df(orig_df):\n",
    "    \"\"\"Remove examples that are of very low count.\"\"\"\n",
    "    MIN_IN_CATEGORY = 1000\n",
    "    df_low_value_counts = orig_df.groupby(CLASS_LABEL_COL).count()\n",
    "    filter_df = df_low_value_counts.reset_index()[df_low_value_counts.reset_index().train > MIN_IN_CATEGORY]\n",
    "    return orig_df.merge(filter_df[CLASS_LABEL_COL], on=CLASS_LABEL_COL, how='inner')\n",
    "\n",
    "def get_remove_missing_and_fix_spelling_df(orig_df):\n",
    "    df = orig_df.copy()\n",
    "    df = df[['text', CLASS_LABEL_COL]]\n",
    "    df = orig_df[orig_df[CLASS_LABEL_COL].str.len() > 0]\n",
    "    df[CLASS_LABEL_COL] = df[CLASS_LABEL_COL].replace({\"causual\": \"casual\"})  # replace spelling mistake in outcomes\n",
    "    df = df[df['text'].notna()]  # exclude rows that are NA\n",
    "    df = df.loc[df['text'].str.strip() != '', :]  # exclude rows with empty string\n",
    "    return df\n",
    "\n",
    "df = orig_df.pipe(get_parsed_df).pipe(get_cleaned_labels_df).pipe(get_remove_missing_and_fix_spelling_df)\n",
    "df = df[['text', CLASS_LABEL_COL]]\n",
    "\n",
    "df.groupby(CLASS_LABEL_COL).count().plot.bar()\n",
    "\n",
    "dataset = Dataset.from_pandas(df, preserve_index=False)\n",
    "dataset = dataset.class_encode_column(CLASS_LABEL_COL)\n",
    "\n",
    "# Need to represent labels columns as tensors\n",
    "labels = [label for label in dataset.features[CLASS_LABEL_COL].names]\n",
    "id2label = {idx:label for idx, label in enumerate(labels)}\n",
    "label2id = {label:idx for idx, label in enumerate(labels)}\n",
    "\n",
    "def to_onehot_tensor(row):\n",
    "    \"\"\" 1-hot encodes a tensor \"\"\"\n",
    "    # Training won't run if don't cast as floats \n",
    "    # https://discuss.pytorch.org/t/multi-label-binary-classification-result-type-float-cant-be-cast-to-the-desired-output-type-long/117915\n",
    "    row['labels_onehot'] = np.eye(len(labels), dtype='uint8')[row[CLASS_LABEL_COL]].astype(np.float32).tolist()\n",
    "    return row\n",
    "\n",
    "dataset = dataset.map(to_onehot_tensor, batched=True)\n",
    "dataset = dataset.rename_column(\"labels_onehot\", \"labels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92329d1a46a443b6af598ae73a685519",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12848 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fbad5846a0d49d08d1349b45c0e39a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3212 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# download tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding='max_length', truncation=True)\n",
    "\n",
    "split_ds = dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "# tokenize dataset\n",
    "train_dataset = split_ds['train'].map(tokenize, batched=True)\n",
    "test_dataset = split_ds['test'].map(tokenize, batched=True)\n",
    "\n",
    "# # set format for pytorch\n",
    "train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': tensor([[0., 1., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.]]),\n",
       " 'input_ids': tensor([[  101,  2054,  2079,  ...,     0,     0,     0],\n",
       "         [  101,  1045,  2572,  ...,     0,     0,     0],\n",
       "         [  101,  1045, 10082,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [  101,  2087,  1997,  ...,     0,     0,     0],\n",
       "         [  101,  1037,  2304,  ...,     0,     0,     0],\n",
       "         [  101,  2339,  2024,  ...,     0,     0,     0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the data\n",
    "dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=10)\n",
    "next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we processed the `datasets` we are going to use the new `FileSystem` [integration](https://huggingface.co/docs/datasets/filesystems.html) to upload our dataset to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6c28580d773444d91c0c634b497df08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/12848 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20388f625c704bb6b3b892fc50ff90b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/3212 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# save train_dataset to s3\n",
    "training_input_path = f's3://{sess.default_bucket()}/{s3_prefix}/train'\n",
    "train_dataset.save_to_disk(training_input_path)\n",
    "\n",
    "# save test_dataset to s3\n",
    "test_input_path = f's3://{sess.default_bucket()}/{s3_prefix}/test'\n",
    "test_dataset.save_to_disk(test_input_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning & starting Sagemaker Training Job\n",
    "\n",
    "In order to create a sagemaker training job we need an `HuggingFace` Estimator. The Estimator handles end-to-end Amazon SageMaker training and deployment tasks. In a Estimator we define, which fine-tuning script should be used as `entry_point`, which `instance_type` should be used, which `hyperparameters` are passed in.\n",
    "You may find `sagemaker` package documentation [here](https://sagemaker.readthedocs.io/en/stable/frameworks/huggingface/sagemaker.huggingface.htmlhttps://sagemaker.readthedocs.io/en/stable/frameworks/huggingface/sagemaker.huggingface.html) for reference.\n",
    "\n",
    "When we create a SageMaker training job, SageMaker takes care of starting and managing all the required ec2 instances for us with the `huggingface` container, pulls the fine-tuning script `train_multi.py` and downloads the data from our `sagemaker_session_bucket` into the container at `/opt/ml/input/data`. Then, it starts the training job by running. \n",
    "\n",
    "```python\n",
    "/opt/conda/bin/python train.py --epochs 1 --model_name distilbert-base-uncased --train_batch_size 32\n",
    "```\n",
    "\n",
    "The `hyperparameters` you define in the `HuggingFace` estimator are passed in as named arguments. \n",
    "\n",
    "Sagemaker is providing useful properties about the training environment through various environment variables, including the following:\n",
    "\n",
    "* `SM_MODEL_DIR`: A string that represents the path where the training job writes the model artifacts to. After training, artifacts in this directory are uploaded to S3 for model hosting.\n",
    "\n",
    "* `SM_NUM_GPUS`: An integer representing the number of GPUs available to the host.\n",
    "\n",
    "* `SM_CHANNEL_XXXX:` A string that represents the path to the directory that contains the input data for the specified channel. For example, if you specify two input channels in the HuggingFace estimator’s fit call, named `train` and `test`, the environment variables `SM_CHANNEL_TRAIN` and `SM_CHANNEL_TEST` are set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtransformers\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m AutoModelForSequenceClassification, Trainer, TrainingArguments, AutoTokenizer\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtransformers\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m EvalPrediction\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmetrics\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m accuracy_score, precision_recall_fscore_support\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmetrics\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m f1_score, roc_auc_score, accuracy_score\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mdatasets\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m load_from_disk\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mrandom\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    parser = argparse.ArgumentParser()\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# hyperparameters sent by the client are passed as command-line arguments to the script.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--epochs\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m3\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--train_batch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m32\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--eval_batch_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m64\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--warmup_steps\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m500\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--model_name\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--learning_rate\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=\u001b[34m5e-5\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Data, model, and output directories\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--output_data_dir\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_OUTPUT_DATA_DIR\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--model_dir\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--n_gpus\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_NUM_GPUS\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--training_dir\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAIN\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--test_dir\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_CHANNEL_TEST\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    args, _ = parser.parse_known_args()\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Set up logging\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    logger = logging.getLogger(\u001b[31m__name__\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    logging.basicConfig(\u001b[37m\u001b[39;49;00m\n",
      "        level=logging.getLevelName(\u001b[33m\"\u001b[39;49;00m\u001b[33mINFO\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
      "        handlers=[logging.StreamHandler(sys.stdout)],\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mformat\u001b[39;49;00m=\u001b[33m\"\u001b[39;49;00m\u001b[33m%(asctime)s\u001b[39;49;00m\u001b[33m - \u001b[39;49;00m\u001b[33m%(name)s\u001b[39;49;00m\u001b[33m - \u001b[39;49;00m\u001b[33m%(levelname)s\u001b[39;49;00m\u001b[33m - \u001b[39;49;00m\u001b[33m%(message)s\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# load datasets\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    train_dataset = load_from_disk(args.training_dir)\u001b[37m\u001b[39;49;00m\n",
      "    test_dataset = load_from_disk(args.test_dir)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m loaded train_dataset length is: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[36mlen\u001b[39;49;00m(train_dataset)\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m loaded test_dataset length is: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[36mlen\u001b[39;49;00m(test_dataset)\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# compute metrics function for binary classification\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# def compute_metrics(pred):\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#     labels = pred.label_ids\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#     preds = pred.predictions.argmax(-1)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#     precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\")\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#     acc = accuracy_score(labels, preds)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#     return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mmulti_label_metrics\u001b[39;49;00m(predictions, labels, threshold=\u001b[34m0.5\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        sigmoid = torch.nn.Sigmoid()\u001b[37m\u001b[39;49;00m\n",
      "        probs = sigmoid(torch.Tensor(predictions))\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# next, use threshold to turn them into integer predictions\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        y_pred = np.zeros(probs.shape)\u001b[37m\u001b[39;49;00m\n",
      "        y_pred[np.where(probs >= threshold)] = \u001b[34m1\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# finally, compute metrics\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        y_true = labels\u001b[37m\u001b[39;49;00m\n",
      "        f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average=\u001b[33m'\u001b[39;49;00m\u001b[33mmicro\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        roc_auc = roc_auc_score(y_true, y_pred, average = \u001b[33m'\u001b[39;49;00m\u001b[33mmicro\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        accuracy = accuracy_score(y_true, y_pred)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# return as dictionary\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        metrics = {\u001b[33m'\u001b[39;49;00m\u001b[33mf1\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: f1_micro_average,\u001b[37m\u001b[39;49;00m\n",
      "                   \u001b[33m'\u001b[39;49;00m\u001b[33mroc_auc\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: roc_auc,\u001b[37m\u001b[39;49;00m\n",
      "                   \u001b[33m'\u001b[39;49;00m\u001b[33maccuracy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: accuracy}\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m metrics\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mcompute_metrics\u001b[39;49;00m(p: EvalPrediction):\u001b[37m\u001b[39;49;00m\n",
      "        preds = p.predictions[\u001b[34m0\u001b[39;49;00m] \u001b[34mif\u001b[39;49;00m \u001b[36misinstance\u001b[39;49;00m(p.predictions, \u001b[37m\u001b[39;49;00m\n",
      "                \u001b[36mtuple\u001b[39;49;00m) \u001b[34melse\u001b[39;49;00m p.predictions\u001b[37m\u001b[39;49;00m\n",
      "        result = multi_label_metrics(\u001b[37m\u001b[39;49;00m\n",
      "            predictions=preds, \u001b[37m\u001b[39;49;00m\n",
      "            labels=p.label_ids)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m result\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Set up multi-class model\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    labels = [label \u001b[34mfor\u001b[39;49;00m label \u001b[35min\u001b[39;49;00m train_dataset.features[\u001b[33m'\u001b[39;49;00m\u001b[33mstr_labels\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m].names]\u001b[37m\u001b[39;49;00m\n",
      "    id2label = {idx:label \u001b[34mfor\u001b[39;49;00m idx, label \u001b[35min\u001b[39;49;00m \u001b[36menumerate\u001b[39;49;00m(labels)}\u001b[37m\u001b[39;49;00m\n",
      "    label2id = {label:idx \u001b[34mfor\u001b[39;49;00m idx, label \u001b[35min\u001b[39;49;00m \u001b[36menumerate\u001b[39;49;00m(labels)}\u001b[37m\u001b[39;49;00m\n",
      "    model = AutoModelForSequenceClassification.from_pretrained(\u001b[37m\u001b[39;49;00m\n",
      "        args.model_name, \u001b[37m\u001b[39;49;00m\n",
      "        problem_type=\u001b[33m\"\u001b[39;49;00m\u001b[33mmulti_label_classification\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[37m\u001b[39;49;00m\n",
      "        num_labels=\u001b[36mlen\u001b[39;49;00m(labels),\u001b[37m\u001b[39;49;00m\n",
      "        id2label=id2label,\u001b[37m\u001b[39;49;00m\n",
      "        label2id=label2id)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    tokenizer = AutoTokenizer.from_pretrained(args.model_name)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# define training args\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    training_args = TrainingArguments(\u001b[37m\u001b[39;49;00m\n",
      "        output_dir=args.model_dir,\u001b[37m\u001b[39;49;00m\n",
      "        num_train_epochs=args.epochs,\u001b[37m\u001b[39;49;00m\n",
      "        per_device_train_batch_size=args.train_batch_size,\u001b[37m\u001b[39;49;00m\n",
      "        per_device_eval_batch_size=args.eval_batch_size,\u001b[37m\u001b[39;49;00m\n",
      "        warmup_steps=args.warmup_steps,\u001b[37m\u001b[39;49;00m\n",
      "        evaluation_strategy=\u001b[33m\"\u001b[39;49;00m\u001b[33mepoch\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        logging_strategy=\u001b[33m\"\u001b[39;49;00m\u001b[33mepoch\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        logging_dir=\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00margs.output_data_dir\u001b[33m}\u001b[39;49;00m\u001b[33m/logs\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        learning_rate=\u001b[36mfloat\u001b[39;49;00m(args.learning_rate),\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# create Trainer instance\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    trainer = Trainer(\u001b[37m\u001b[39;49;00m\n",
      "        model=model,\u001b[37m\u001b[39;49;00m\n",
      "        args=training_args,\u001b[37m\u001b[39;49;00m\n",
      "        compute_metrics=compute_metrics,\u001b[37m\u001b[39;49;00m\n",
      "        train_dataset=train_dataset,\u001b[37m\u001b[39;49;00m\n",
      "        eval_dataset=test_dataset,\u001b[37m\u001b[39;49;00m\n",
      "        tokenizer=tokenizer,\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# train model\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    trainer.train()\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# evaluate model\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    eval_result = trainer.evaluate(eval_dataset=test_dataset)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# writes eval result to file which can be accessed later in s3 ouput\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(os.path.join(args.output_data_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33meval_results.txt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m), \u001b[33m\"\u001b[39;49;00m\u001b[33mw\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m writer:\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m***** Eval results *****\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mfor\u001b[39;49;00m key, value \u001b[35min\u001b[39;49;00m \u001b[36msorted\u001b[39;49;00m(eval_result.items()):\u001b[37m\u001b[39;49;00m\n",
      "            writer.write(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mkey\u001b[33m}\u001b[39;49;00m\u001b[33m = \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mvalue\u001b[33m}\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Saves the model to s3\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    trainer.save_model(args.model_dir)\u001b[37m\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "!pygmentize ./scripts/train_multiclass.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a DISTRIBUTED Estimator and Start Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "# configuration for running training on smdistributed Data Parallel\n",
    "\n",
    "distribution = {'smdistributed':{'dataparallel':{ 'enabled': True }}}\n",
    "instance_type = 'ml.p3.16xlarge'\n",
    "instance_count = 2\n",
    "\n",
    "\n",
    "# hyperparameters, which are passed into the training job\n",
    "# Don't forget 'model_name'!\n",
    "hyperparameters={\n",
    "    'model_name':'distilbert-base-uncased',\n",
    "    'model_id': tokenizer_name,\n",
    "    'epochs': 3,\n",
    "    'per_device_train_batch_size': 32,\n",
    "    'per_device_eval_batch_size': 32,\n",
    "    'learning_rate': 3e-5,\n",
    "    'fp16': True,\n",
    "    'save_total_limit':2,\n",
    "    'load_best_model_at_end':True,\n",
    "    'metric_for_best_model':\"f1\",\n",
    "    'doc_stride': 128,\n",
    "    'pad_to_max_length': True,\n",
    "    'output_dir': '/opt/ml/model'\n",
    "}\n",
    "\n",
    "\n",
    "# This git config is important as each instance will need to pull the train_multiclass.py separately.\n",
    "git_config = {'repo': 'https://github.com/edlee123/notebooks.git','branch': 'multiclass-distributed'}\n",
    "\n",
    "\n",
    "metric_definitions=[\n",
    "     {\"Name\": \"train_runtime\", \"Regex\": \"train_runtime.*=\\D*(.*?)$\"},\n",
    "     {'Name': 'train_samples_per_second', 'Regex': \"train_samples_per_second.*=\\D*(.*?)$\"},\n",
    "     {'Name': 'epoch', 'Regex': \"epoch.*=\\D*(.*?)$\"},\n",
    "     {'Name': 'f1', 'Regex': \"f1.*=\\D*(.*?)$\"},\n",
    "     {'Name': 'exact_match', 'Regex': \"exact_match.*=\\D*(.*?)$\"}]\n",
    "volume_size = 200\n",
    "\n",
    "\n",
    "# this estimator needs to pull the entry_point file in distributed mode.\n",
    "huggingface_estimator = HuggingFace(entry_point='train_multiclass.py',\n",
    "                            source_dir=\"sagemaker/29-multiclass_dataparallelism/scripts\",\n",
    "                            git_config=git_config,\n",
    "                            metric_definitions=metric_definitions,\n",
    "                            instance_type=instance_type,\n",
    "                            instance_count=instance_count,\n",
    "                            volume_size=volume_size,\n",
    "                            # use_spot_instances=True,\n",
    "        # max_wait should be equal to or greater than max_run in seconds\n",
    "                            # max_wait=3600,\n",
    "                            # max_run=1000,\n",
    "                            role=role,\n",
    "                            transformers_version='4.26.0',\n",
    "                            pytorch_version='1.13.1',\n",
    "                            py_version='py39',\n",
    "                            distribution=distribution,\n",
    "                            hyperparameters=hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Start the train job with our uploaded datasets as input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: huggingface-pytorch-training-2023-10-27-01-49-55-845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n",
      "2023-10-27 01:50:11 Starting - Starting the training job......\n",
      "2023-10-27 01:51:07 Starting - Preparing the instances for training.........\n",
      "2023-10-27 01:52:36 Downloading - Downloading input data\n",
      "2023-10-27 01:52:36 Training - Downloading the training image..............................\n",
      "2023-10-27 01:57:33 Training - Training image download completed. Training in progress...\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-10-27 01:57:55,807 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-10-27 01:57:55,869 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-10-27 01:57:55,881 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-10-27 01:57:55,884 sagemaker_pytorch_container.training INFO     Invoking SMDataParallel\u001b[0m\n",
      "\u001b[34m2023-10-27 01:57:55,884 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-10-27 01:57:56,203 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-10-27 01:57:56,280 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-10-27 01:57:56,293 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\u001b[0m\n",
      "\u001b[34m2023-10-27 01:57:56,293 sagemaker-training-toolkit INFO     Waiting for MPI Master to create SSH daemon.\u001b[0m\n",
      "\u001b[34m2023-10-27 01:57:56,294 sagemaker-training-toolkit INFO     Cannot connect to host algo-1\u001b[0m\n",
      "\u001b[34m2023-10-27 01:57:56,294 sagemaker-training-toolkit INFO     Connection failed with exception: \n",
      " [Errno None] Unable to connect to port 22 on 10.0.188.173.              Can be ignored for worker when master completes and exits.\u001b[0m\n",
      "\u001b[34m2023-10-27 01:57:57,296 sagemaker-training-toolkit INFO     Cannot connect to host algo-1\u001b[0m\n",
      "\u001b[34m2023-10-27 01:57:57,296 sagemaker-training-toolkit INFO     Connection failed with exception: \n",
      " [Errno None] Unable to connect to port 22 on 10.0.188.173.              Can be ignored for worker when master completes and exits.\u001b[0m\n",
      "\u001b[34m2023-10-27 01:57:58,298 sagemaker-training-toolkit INFO     Cannot connect to host algo-1\u001b[0m\n",
      "\u001b[34m2023-10-27 01:57:58,298 sagemaker-training-toolkit INFO     Connection failed with exception: \n",
      " [Errno None] Unable to connect to port 22 on 10.0.188.173.              Can be ignored for worker when master completes and exits.\u001b[0m\n",
      "\u001b[34m2023-10-27 01:57:59,300 sagemaker-training-toolkit INFO     Cannot connect to host algo-1\u001b[0m\n",
      "\u001b[34m2023-10-27 01:57:59,300 sagemaker-training-toolkit INFO     Connection failed with exception: \n",
      " [Errno None] Unable to connect to port 22 on 10.0.188.173.              Can be ignored for worker when master completes and exits.\u001b[0m\n",
      "\u001b[34m2023-10-27 01:58:00,301 sagemaker-training-toolkit INFO     Cannot connect to host algo-1\u001b[0m\n",
      "\u001b[34m2023-10-27 01:58:00,302 sagemaker-training-toolkit INFO     Connection failed with exception: \n",
      " [Errno None] Unable to connect to port 22 on 10.0.188.173.              Can be ignored for worker when master completes and exits.\u001b[0m\n",
      "\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-10-27 01:58:00,171 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-10-27 01:58:00,233 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-10-27 01:58:00,246 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-10-27 01:58:00,249 sagemaker_pytorch_container.training INFO     Invoking SMDataParallel\u001b[0m\n",
      "\u001b[34m2023-10-27 01:58:00,249 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-10-27 01:58:00,568 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-10-27 01:58:00,645 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-10-27 01:58:00,659 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\u001b[0m\n",
      "\u001b[34m2023-10-27 01:58:00,659 sagemaker-training-toolkit INFO     Creating SSH daemon.\u001b[0m\n",
      "\u001b[34m2023-10-27 01:58:00,661 sagemaker-training-toolkit INFO     Waiting for MPI workers to establish their SSH connections\u001b[0m\n",
      "\u001b[34m2023-10-27 01:58:00,662 sagemaker-training-toolkit INFO     Cannot connect to host algo-2 at port 22. Retrying...\u001b[0m\n",
      "\u001b[34m2023-10-27 01:58:00,662 sagemaker-training-toolkit INFO     Connection closed\u001b[0m\n",
      "\u001b[35m2023-10-27 01:58:01,315 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_8.2p1)\u001b[0m\n",
      "\u001b[35m2023-10-27 01:58:01,483 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[35m2023-10-27 01:58:01,483 sagemaker-training-toolkit INFO     Can connect to host algo-1\u001b[0m\n",
      "\u001b[35m2023-10-27 01:58:01,483 sagemaker-training-toolkit INFO     MPI Master online, creating SSH daemon.\u001b[0m\n",
      "\u001b[35m2023-10-27 01:58:01,483 sagemaker-training-toolkit INFO     Writing environment variables to /etc/environment for the MPI process.\u001b[0m\n",
      "\u001b[35m2023-10-27 01:58:01,488 sagemaker-training-toolkit INFO     Waiting for MPI process to finish.\u001b[0m\n",
      "\u001b[34m2023-10-27 01:58:01,676 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_8.2p1)\u001b[0m\n",
      "\u001b[34m2023-10-27 01:58:01,843 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[34m2023-10-27 01:58:01,843 sagemaker-training-toolkit INFO     Can connect to host algo-2 at port 22\u001b[0m\n",
      "\u001b[34m2023-10-27 01:58:01,843 sagemaker-training-toolkit INFO     Connection closed\u001b[0m\n",
      "\u001b[34m2023-10-27 01:58:01,843 sagemaker-training-toolkit INFO     Worker algo-2 available for communication\u001b[0m\n",
      "\u001b[34m2023-10-27 01:58:01,843 sagemaker-training-toolkit INFO     Network interface name: eth0\u001b[0m\n",
      "\u001b[34m2023-10-27 01:58:01,843 sagemaker-training-toolkit INFO     Host: ['algo-1', 'algo-2']\u001b[0m\n",
      "\u001b[34m2023-10-27 01:58:01,845 sagemaker-training-toolkit INFO     sagemaker_communication_backend: None\u001b[0m\n",
      "\u001b[34m2023-10-27 01:58:01,845 sagemaker-training-toolkit WARNING  Missing library /opt/conda/lib/libsmddp.so for SMDDP collective\u001b[0m\n",
      "\u001b[34m2023-10-27 01:58:01,845 sagemaker-training-toolkit WARNING  The system is not configured to run SMDDP collectives optimizedfor AWS infrastructure.Please use the latest SageMaker Deep Learning Container (DLC) to enable SMDDP Collectives support.\u001b[0m\n",
      "\u001b[34mContinuing model training with default NCCL communication backend.\u001b[0m\n",
      "\u001b[34m2023-10-27 01:58:01,845 sagemaker-training-toolkit INFO     instance type: ml.p3.16xlarge\u001b[0m\n",
      "\u001b[34m2023-10-27 01:58:01,845 sagemaker-training-toolkit INFO     Env Hosts: ['algo-1', 'algo-2'] Hosts: ['algo-1:8', 'algo-2:8'] process_per_hosts: 8 num_processes: 16\u001b[0m\n",
      "\u001b[34m2023-10-27 01:58:01,935 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-10-27 01:58:01,950 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_distributed_dataparallel_custom_mpi_options\": \"\",\n",
      "        \"sagemaker_distributed_dataparallel_enabled\": true,\n",
      "        \"sagemaker_instance_type\": \"ml.p3.16xlarge\"\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.p3.16xlarge\",\n",
      "    \"distribution_hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"distribution_instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"doc_stride\": 128,\n",
      "        \"epochs\": 3,\n",
      "        \"fp16\": true,\n",
      "        \"learning_rate\": 3e-05,\n",
      "        \"load_best_model_at_end\": true,\n",
      "        \"metric_for_best_model\": \"f1\",\n",
      "        \"model_id\": \"distilbert-base-uncased\",\n",
      "        \"model_name\": \"distilbert-base-uncased\",\n",
      "        \"output_dir\": \"/opt/ml/model\",\n",
      "        \"pad_to_max_length\": true,\n",
      "        \"per_device_eval_batch_size\": 32,\n",
      "        \"per_device_train_batch_size\": 32,\n",
      "        \"save_total_limit\": 2\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.p3.16xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\",\n",
      "                \"algo-2\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"huggingface-pytorch-training-2023-10-27-01-49-55-845\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-391015568214/huggingface-pytorch-training-2023-10-27-01-49-55-845/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_multiclass\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 64,\n",
      "    \"num_gpus\": 8,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.16xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.16xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\",\n",
      "                    \"algo-2\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_multiclass.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"doc_stride\":128,\"epochs\":3,\"fp16\":true,\"learning_rate\":3e-05,\"load_best_model_at_end\":true,\"metric_for_best_model\":\"f1\",\"model_id\":\"distilbert-base-uncased\",\"model_name\":\"distilbert-base-uncased\",\"output_dir\":\"/opt/ml/model\",\"pad_to_max_length\":true,\"per_device_eval_batch_size\":32,\"per_device_train_batch_size\":32,\"save_total_limit\":2}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_multiclass.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_distributed_dataparallel_custom_mpi_options\":\"\",\"sagemaker_distributed_dataparallel_enabled\":true,\"sagemaker_instance_type\":\"ml.p3.16xlarge\"}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.16xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.p3.16xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_multiclass\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=64\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-391015568214/huggingface-pytorch-training-2023-10-27-01-49-55-845/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_distributed_dataparallel_custom_mpi_options\":\"\",\"sagemaker_distributed_dataparallel_enabled\":true,\"sagemaker_instance_type\":\"ml.p3.16xlarge\"},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\",\"algo-2\"],\"current_instance_type\":\"ml.p3.16xlarge\",\"distribution_hosts\":[\"algo-1\",\"algo-2\"],\"distribution_instance_groups\":[\"homogeneousCluster\"],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"doc_stride\":128,\"epochs\":3,\"fp16\":true,\"learning_rate\":3e-05,\"load_best_model_at_end\":true,\"metric_for_best_model\":\"f1\",\"model_id\":\"distilbert-base-uncased\",\"model_name\":\"distilbert-base-uncased\",\"output_dir\":\"/opt/ml/model\",\"pad_to_max_length\":true,\"per_device_eval_batch_size\":32,\"per_device_train_batch_size\":32,\"save_total_limit\":2},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"huggingface-pytorch-training-2023-10-27-01-49-55-845\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-391015568214/huggingface-pytorch-training-2023-10-27-01-49-55-845/source/sourcedir.tar.gz\",\"module_name\":\"train_multiclass\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.16xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_multiclass.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--doc_stride\",\"128\",\"--epochs\",\"3\",\"--fp16\",\"True\",\"--learning_rate\",\"3e-05\",\"--load_best_model_at_end\",\"True\",\"--metric_for_best_model\",\"f1\",\"--model_id\",\"distilbert-base-uncased\",\"--model_name\",\"distilbert-base-uncased\",\"--output_dir\",\"/opt/ml/model\",\"--pad_to_max_length\",\"True\",\"--per_device_eval_batch_size\",\"32\",\"--per_device_train_batch_size\",\"32\",\"--save_total_limit\",\"2\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_DOC_STRIDE=128\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=3\u001b[0m\n",
      "\u001b[34mSM_HP_FP16=true\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=3e-05\u001b[0m\n",
      "\u001b[34mSM_HP_LOAD_BEST_MODEL_AT_END=true\u001b[0m\n",
      "\u001b[34mSM_HP_METRIC_FOR_BEST_MODEL=f1\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_ID=distilbert-base-uncased\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_NAME=distilbert-base-uncased\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_HP_PAD_TO_MAX_LENGTH=true\u001b[0m\n",
      "\u001b[34mSM_HP_PER_DEVICE_EVAL_BATCH_SIZE=32\u001b[0m\n",
      "\u001b[34mSM_HP_PER_DEVICE_TRAIN_BATCH_SIZE=32\u001b[0m\n",
      "\u001b[34mSM_HP_SAVE_TOTAL_LIMIT=2\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python39.zip:/opt/conda/lib/python3.9:/opt/conda/lib/python3.9/lib-dynload:/opt/conda/lib/python3.9/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34mmpirun --host algo-1:8,algo-2:8 -np 16 --allow-run-as-root --tag-output --oversubscribe -mca btl_tcp_if_include eth0 -mca oob_tcp_if_include eth0 -mca plm_rsh_no_tree_spawn 1 -mca pml ob1 -mca btl ^openib -mca orte_abort_on_non_zero_status 1 -mca btl_vader_single_copy_mechanism none -mca plm_rsh_num_concurrent 2 -x NCCL_SOCKET_IFNAME=eth0 -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH -x SMDATAPARALLEL_USE_HOMOGENEOUS=1 -x FI_PROVIDER=efa -x RDMAV_FORK_SAFE=1 -x LD_PRELOAD=/opt/conda/lib/python3.9/site-packages/gethostname.cpython-39-x86_64-linux-gnu.so -x SMDATAPARALLEL_SERVER_ADDR=algo-1 -x SMDATAPARALLEL_SERVER_PORT=7592 -x SAGEMAKER_INSTANCE_TYPE=ml.p3.16xlarge -x USE_SMDDP_COLLECTIVES=0 smddprun /opt/conda/bin/python3.9 -m mpi4py train_multiclass.py --doc_stride 128 --epochs 3 --fp16 True --learning_rate 3e-05 --load_best_model_at_end True --metric_for_best_model f1 --model_id distilbert-base-uncased --model_name distilbert-base-uncased --output_dir /opt/ml/model --pad_to_max_length True --per_device_eval_batch_size 32 --per_device_train_batch_size 32 --save_total_limit 2\u001b[0m\n",
      "\u001b[34m[2023-10-27 01:58:04.155: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.26.0 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34m2023-10-27 01:58:04,162 root         INFO     Using NamedTuple = typing._NamedTuple instead.\u001b[0m\n",
      "\u001b[34mWarning: Permanently added 'algo-2,10.0.150.11' (ECDSA) to the list of known hosts.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\u001b[0m\n",
      "\u001b[35m2023-10-27 01:58:05,504 sagemaker-training-toolkit INFO     Process[es]: [psutil.Process(pid=58, name='orted', status='sleeping', started='01:58:04')]\u001b[0m\n",
      "\u001b[35m2023-10-27 01:58:05,504 sagemaker-training-toolkit INFO     Orted process found [psutil.Process(pid=58, name='orted', status='sleeping', started='01:58:04')]\u001b[0m\n",
      "\u001b[35m2023-10-27 01:58:05,505 sagemaker-training-toolkit INFO     Waiting for orted process [psutil.Process(pid=58, name='orted', status='sleeping', started='01:58:04')]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:2023-10-27 01:58:08,868 - __main__ - INFO -  loaded train_dataset length is: 12848\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:2023-10-27 01:58:08,868 - __main__ - INFO -  loaded test_dataset length is: 3212\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:2023-10-27 01:58:08,870 - __main__ - INFO -  loaded train_dataset length is: 12848\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:2023-10-27 01:58:08,870 - __main__ - INFO -  loaded test_dataset length is: 3212\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:2023-10-27 01:58:08,871 - __main__ - INFO -  loaded train_dataset length is: 12848\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:2023-10-27 01:58:08,871 - __main__ - INFO -  loaded test_dataset length is: 3212\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:2023-10-27 01:58:08,892 - __main__ - INFO -  loaded train_dataset length is: 12848\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:2023-10-27 01:58:08,893 - __main__ - INFO -  loaded test_dataset length is: 3212\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:2023-10-27 01:58:08,892 - __main__ - INFO -  loaded train_dataset length is: 12848\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:2023-10-27 01:58:08,892 - __main__ - INFO -  loaded test_dataset length is: 3212\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:2023-10-27 01:58:08,893 - __main__ - INFO -  loaded train_dataset length is: 12848\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:2023-10-27 01:58:08,893 - __main__ - INFO -  loaded test_dataset length is: 3212\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:2023-10-27 01:58:08,910 - __main__ - INFO -  loaded train_dataset length is: 12848\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:2023-10-27 01:58:08,911 - __main__ - INFO -  loaded test_dataset length is: 3212\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:2023-10-27 01:58:08,926 - __main__ - INFO -  loaded train_dataset length is: 12848\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:2023-10-27 01:58:08,926 - __main__ - INFO -  loaded test_dataset length is: 3212\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:2023-10-27 01:58:08,941 - __main__ - INFO -  loaded train_dataset length is: 12848\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:2023-10-27 01:58:08,941 - __main__ - INFO -  loaded test_dataset length is: 3212\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:2023-10-27 01:58:08,966 - __main__ - INFO -  loaded train_dataset length is: 12848\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:2023-10-27 01:58:08,966 - __main__ - INFO -  loaded test_dataset length is: 3212\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:2023-10-27 01:58:08,973 - __main__ - INFO -  loaded train_dataset length is: 12848\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:2023-10-27 01:58:08,973 - __main__ - INFO -  loaded test_dataset length is: 3212\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:2023-10-27 01:58:08,979 - __main__ - INFO -  loaded train_dataset length is: 12848\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:2023-10-27 01:58:08,979 - __main__ - INFO -  loaded test_dataset length is: 3212\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:2023-10-27 01:58:08,995 - __main__ - INFO -  loaded train_dataset length is: 12848\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:2023-10-27 01:58:08,995 - __main__ - INFO -  loaded test_dataset length is: 3212\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015Downloading (…)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:2023-10-27 01:58:09,018 - __main__ - INFO -  loaded train_dataset length is: 12848\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:2023-10-27 01:58:09,018 - __main__ - INFO -  loaded test_dataset length is: 3212\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015Downloading (…)lve/main/config.json: 100%|██████████| 483/483 [00:00<00:00, 62.3kB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:2023-10-27 01:58:09,124 - __main__ - INFO -  loaded train_dataset length is: 12848\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:2023-10-27 01:58:09,124 - __main__ - INFO -  loaded test_dataset length is: 3212\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015Downloading (…)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015Downloading (…)lve/main/config.json: 100%|██████████| 483/483 [00:00<00:00, 62.0kB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:2023-10-27 01:58:09,187 - __main__ - INFO -  loaded train_dataset length is: 12848\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:2023-10-27 01:58:09,187 - __main__ - INFO -  loaded test_dataset length is: 3212\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/268M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015Downloading (…)\"pytorch_model.bin\";:  12%|█▏        | 31.5M/268M [00:00<00:00, 276MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/268M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015Downloading (…)\"pytorch_model.bin\";:  27%|██▋       | 73.4M/268M [00:00<00:00, 354MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015Downloading (…)\"pytorch_model.bin\";:  12%|█▏        | 31.5M/268M [00:00<00:00, 289MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015Downloading (…)\"pytorch_model.bin\";:  43%|████▎     | 115M/268M [00:00<00:00, 360MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015Downloading (…)\"pytorch_model.bin\";:  23%|██▎       | 62.9M/268M [00:00<00:00, 289MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015Downloading (…)\"pytorch_model.bin\";:  59%|█████▊    | 157M/268M [00:00<00:00, 368MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015Downloading (…)\"pytorch_model.bin\";:  39%|███▉      | 105M/268M [00:00<00:00, 342MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015Downloading (…)\"pytorch_model.bin\";:  74%|███████▍  | 199M/268M [00:00<00:00, 358MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015Downloading (…)\"pytorch_model.bin\";:  55%|█████▍    | 147M/268M [00:00<00:00, 371MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015Downloading (…)\"pytorch_model.bin\";:  70%|███████   | 189M/268M [00:00<00:00, 381MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015Downloading (…)\"pytorch_model.bin\";:  90%|█████████ | 241M/268M [00:00<00:00, 338MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015Downloading (…)\"pytorch_model.bin\";: 100%|██████████| 268M/268M [00:00<00:00, 344MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015Downloading (…)\"pytorch_model.bin\";:  86%|████████▌ | 231M/268M [00:00<00:00, 384MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015Downloading (…)\"pytorch_model.bin\";: 100%|██████████| 268M/268M [00:00<00:00, 348MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'classifier.weight']\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'classifier.weight']\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight']\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight']\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias']\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'classifier.bias', 'pre_classifier.weight']\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias']\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'classifier.bias', 'pre_classifier.weight']\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight']\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight']\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.weight', 'pre_classifier.bias']\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.weight', 'pre_classifier.bias']\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_projector.bias']\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_projector.bias']\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.bias']\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.bias']\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias']\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias']\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias']\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias']\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'classifier.bias', 'pre_classifier.bias']\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'classifier.bias', 'pre_classifier.bias']\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_projector.weight']\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_projector.weight']\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.weight', 'pre_classifier.bias']\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.weight', 'pre_classifier.bias']\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias', 'classifier.bias']\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias', 'classifier.bias']\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight']\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias']\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight']\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias']\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight']\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight']\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015Downloading (…)okenizer_config.json: 100%|██████████| 28.0/28.0 [00:00<00:00, 8.48kB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight']\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight']\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight']\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight']\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_transform.bias']\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias', 'classifier.bias']\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_transform.bias']\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias', 'classifier.bias']\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight']\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias']\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight']\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias']\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias']\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias', 'classifier.bias']\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias']\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias', 'classifier.bias']\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.weight']\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.weight', 'pre_classifier.bias']\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.weight']\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.weight', 'pre_classifier.bias']\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015Downloading (…)okenizer_config.json: 100%|██████████| 28.0/28.0 [00:00<00:00, 10.7kB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015Downloading (…)solve/main/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 15.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015Downloading (…)/main/tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 21.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015Downloading (…)solve/main/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 3.86MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015Downloading (…)/main/tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 6.08MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:DDP Mode\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:DDP Mode\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:DDP Mode\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:DDP Mode\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:DDP Mode\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:DDP Mode\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:DDP Mode\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:DDP Mode\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:DDP Mode\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:DDP Mode\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:DDP Mode\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:DDP Mode\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:DDP Mode\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:DDP Mode\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:DDP Mode\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:DDP Mode\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Bootstrap : Using eth0:10.0.188.173<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO cudaDriverVersion 12020\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO cudaDriverVersion 12020\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO cudaDriverVersion 12020\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO cudaDriverVersion 12020\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO cudaDriverVersion 12020\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO cudaDriverVersion 12020\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO cudaDriverVersion 12020\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO cudaDriverVersion 12020\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:NCCL version 2.14.3+cuda11.7[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO cudaDriverVersion 12020\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO cudaDriverVersion 12020\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO cudaDriverVersion 12020\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO cudaDriverVersion 12020\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO cudaDriverVersion 12020\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO cudaDriverVersion 12020\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO cudaDriverVersion 12020\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO cudaDriverVersion 12020\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO NET/OFI Using aws-ofi-nccl 1.4.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] ofi_init:1355 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO NET/Socket : Using [0]eth0:10.0.188.173<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Bootstrap : Using eth0:10.0.188.173<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Bootstrap : Using eth0:10.0.150.11<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Bootstrap : Using eth0:10.0.188.173<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO NET/OFI Using aws-ofi-nccl 1.4.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO NET/OFI Using aws-ofi-nccl 1.4.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO NET/OFI Using aws-ofi-nccl 1.4.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] ofi_init:1355 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO NET/Socket : Using [0]eth0:10.0.150.11<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] ofi_init:1355 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO NET/Socket : Using [0]eth0:10.0.188.173<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] ofi_init:1355 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO NET/Socket : Using [0]eth0:10.0.188.173<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Bootstrap : Using eth0:10.0.188.173<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Bootstrap : Using eth0:10.0.150.11<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Bootstrap : Using eth0:10.0.150.11<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Bootstrap : Using eth0:10.0.188.173<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO NET/OFI Using aws-ofi-nccl 1.4.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO NET/OFI Using aws-ofi-nccl 1.4.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO NET/OFI Using aws-ofi-nccl 1.4.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO NET/OFI Using aws-ofi-nccl 1.4.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Bootstrap : Using eth0:10.0.150.11<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] ofi_init:1355 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO NET/Socket : Using [0]eth0:10.0.188.173<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] ofi_init:1355 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO NET/Socket : Using [0]eth0:10.0.150.11<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] ofi_init:1355 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] ofi_init:1355 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO NET/Socket : Using [0]eth0:10.0.188.173<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO NET/Socket : Using [0]eth0:10.0.150.11<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO NET/OFI Using aws-ofi-nccl 1.4.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] ofi_init:1355 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO NET/Socket : Using [0]eth0:10.0.150.11<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Bootstrap : Using eth0:10.0.188.173<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO NET/OFI Using aws-ofi-nccl 1.4.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] ofi_init:1355 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO NET/Socket : Using [0]eth0:10.0.188.173<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Bootstrap : Using eth0:10.0.188.173<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO NET/OFI Using aws-ofi-nccl 1.4.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] ofi_init:1355 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO NET/Socket : Using [0]eth0:10.0.188.173<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Bootstrap : Using eth0:10.0.188.173<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO NET/OFI Using aws-ofi-nccl 1.4.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Bootstrap : Using eth0:10.0.150.11<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] ofi_init:1355 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO NET/Socket : Using [0]eth0:10.0.188.173<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO NET/OFI Using aws-ofi-nccl 1.4.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] ofi_init:1355 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO NET/Socket : Using [0]eth0:10.0.150.11<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Bootstrap : Using eth0:10.0.150.11<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO NET/OFI Using aws-ofi-nccl 1.4.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] ofi_init:1355 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO NET/Socket : Using [0]eth0:10.0.150.11<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Bootstrap : Using eth0:10.0.150.11<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO NET/OFI Using aws-ofi-nccl 1.4.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] ofi_init:1355 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO NET/Socket : Using [0]eth0:10.0.150.11<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Bootstrap : Using eth0:10.0.150.11<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO NET/OFI Using aws-ofi-nccl 1.4.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] ofi_init:1355 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO NET/Socket : Using [0]eth0:10.0.150.11<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Trees [0] 4/-1/-1->7->6 [1] 4/-1/-1->7->6\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Trees [0] 10/-1/-1->11->8 [1] 10/-1/-1->11->8\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Trees [0] 5/-1/-1->1->2 [1] 5/-1/-1->1->2\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Trees [0] 6/-1/-1->5->1 [1] 6/-1/-1->5->1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Channel 00/02 :    0   3   2   1   5   6   7   4   8  11  10   9  13  14  15  12\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Channel 01/02 :    0   3   2   1   5   6   7   4   8  11  10   9  13  14  15  12\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Trees [0] 3/8/-1->0->-1 [1] 3/-1/-1->0->8\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Trees [0] -1/-1/-1->4->7 [1] -1/-1/-1->4->7\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Trees [0] 2/-1/-1->3->0 [1] 2/-1/-1->3->0\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Trees [0] 1/-1/-1->2->3 [1] 1/-1/-1->2->3\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Trees [0] 9/-1/-1->10->11 [1] 9/-1/-1->10->11\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Trees [0] 15/-1/-1->14->13 [1] 15/-1/-1->14->13\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Trees [0] 14/-1/-1->13->9 [1] 14/-1/-1->13->9\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Trees [0] -1/-1/-1->12->15 [1] -1/-1/-1->12->15\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Trees [0] 12/-1/-1->15->14 [1] 12/-1/-1->15->14\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Trees [0] 13/-1/-1->9->10 [1] 13/-1/-1->9->10\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Trees [0] 11/-1/-1->8->0 [1] 11/0/-1->8->-1\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Channel 00/0 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Channel 00/0 : 13[1c0] -> 14[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Channel 00/0 : 9[180] -> 13[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Channel 00/0 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Channel 00/0 : 8[170] -> 11[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Channel 00/0 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Channel 01/0 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Channel 01/0 : 13[1c0] -> 14[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Channel 01/0 : 9[180] -> 13[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Channel 01/0 : 8[170] -> 11[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Channel 01/0 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Channel 01/0 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Channel 00/0 : 10[190] -> 9[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Channel 00/0 : 14[1d0] -> 15[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Channel 00/0 : 12[1b0] -> 0[170] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Channel 00/0 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Channel 00/0 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Channel 00/0 : 4[1b0] -> 8[170] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Channel 01/0 : 10[190] -> 9[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Channel 01/0 : 14[1d0] -> 15[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Channel 01/0 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Channel 00/0 : 11[1a0] -> 10[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Channel 01/0 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Channel 00/0 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Channel 01/0 : 11[1a0] -> 10[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Channel 01/0 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Channel 00/0 : 15[1e0] -> 12[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Channel 00/0 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Channel 01/0 : 15[1e0] -> 12[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Channel 01/0 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Channel 00/0 : 13[1c0] -> 9[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Channel 00/0 : 14[1d0] -> 13[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Channel 00/0 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Channel 01/0 : 13[1c0] -> 9[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Channel 00/0 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Channel 01/0 : 14[1d0] -> 13[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Channel 01/0 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Channel 01/0 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Channel 00/0 : 9[180] -> 10[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Channel 00/0 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Channel 01/0 : 9[180] -> 10[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Channel 01/0 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Channel 00/0 : 10[190] -> 11[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Channel 00/0 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Channel 01/0 : 10[190] -> 11[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Channel 01/0 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Channel 00/0 : 11[1a0] -> 8[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Channel 00/0 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Channel 01/0 : 11[1a0] -> 8[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Channel 00/1 : 10[190] -> 12[1b0] via P2P/indirect/8[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Channel 01/0 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Channel 00/1 : 2[190] -> 4[1b0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Channel 00/1 : 9[180] -> 12[1b0] via P2P/indirect/8[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Channel 00/1 : 1[180] -> 4[1b0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Channel 01/1 : 10[190] -> 12[1b0] via P2P/indirect/8[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Channel 01/1 : 2[190] -> 4[1b0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Channel 01/1 : 9[180] -> 12[1b0] via P2P/indirect/8[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Channel 01/1 : 1[180] -> 4[1b0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Channel 01/0 : 4[1b0] -> 8[170] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:1345 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Channel 00/0 : 12[1b0] -> 0[170] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Channel 01/0 : 12[1b0] -> 0[170] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:1278 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Channel 00/0 : 4[1b0] -> 8[170] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:1345 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Channel 01/0 : 12[1b0] -> 0[170] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:1278 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Channel 01/0 : 4[1b0] -> 8[170] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Channel 00/0 : 12[1b0] -> 15[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Channel 01/0 : 12[1b0] -> 15[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Channel 00/0 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Channel 01/0 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Channel 00/0 : 15[1e0] -> 14[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Channel 01/0 : 15[1e0] -> 14[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Channel 00/0 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Channel 01/0 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:1345 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Channel 00/0 : 8[170] -> 0[170] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:1278 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Channel 00/0 : 0[170] -> 8[170] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:1345 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Channel 01/0 : 8[170] -> 0[170] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:1278 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Channel 01/0 : 0[170] -> 8[170] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Channel 00/0 : 0[170] -> 8[170] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Channel 00/0 : 8[170] -> 0[170] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Channel 01/0 : 0[170] -> 8[170] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Channel 01/0 : 8[170] -> 0[170] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Channel 00/1 : 0[170] -> 5[1c0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Channel 00/1 : 8[170] -> 13[1c0] via P2P/indirect/9[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Channel 00/1 : 3[1a0] -> 4[1b0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Channel 00/1 : 11[1a0] -> 12[1b0] via P2P/indirect/8[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Channel 01/1 : 11[1a0] -> 12[1b0] via P2P/indirect/8[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Channel 01/1 : 3[1a0] -> 4[1b0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Channel 01/1 : 0[170] -> 5[1c0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Channel 01/1 : 8[170] -> 13[1c0] via P2P/indirect/9[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Channel 00/1 : 11[1a0] -> 13[1c0] via P2P/indirect/9[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Channel 00/1 : 3[1a0] -> 5[1c0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Channel 01/1 : 11[1a0] -> 13[1c0] via P2P/indirect/9[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Channel 01/1 : 3[1a0] -> 5[1c0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Channel 00/1 : 11[1a0] -> 14[1d0] via P2P/indirect/15[1e0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Channel 00/1 : 10[190] -> 13[1c0] via P2P/indirect/9[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Channel 00/1 : 3[1a0] -> 6[1d0] via P2P/indirect/7[1e0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Channel 00/1 : 2[190] -> 5[1c0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Channel 01/1 : 11[1a0] -> 14[1d0] via P2P/indirect/15[1e0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Channel 01/1 : 3[1a0] -> 6[1d0] via P2P/indirect/7[1e0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Channel 01/1 : 10[190] -> 13[1c0] via P2P/indirect/9[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Channel 01/1 : 2[190] -> 5[1c0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Channel 00/1 : 10[190] -> 15[1e0] via P2P/indirect/14[1d0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Channel 00/1 : 12[1b0] -> 9[180] via P2P/indirect/13[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Channel 00/1 : 9[180] -> 14[1d0] via P2P/indirect/13[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Channel 00/1 : 4[1b0] -> 1[180] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Channel 00/1 : 1[180] -> 6[1d0] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Channel 00/1 : 2[190] -> 7[1e0] via P2P/indirect/6[1d0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Channel 01/1 : 12[1b0] -> 9[180] via P2P/indirect/13[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Channel 01/1 : 4[1b0] -> 1[180] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Channel 01/1 : 10[190] -> 15[1e0] via P2P/indirect/14[1d0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Channel 01/1 : 9[180] -> 14[1d0] via P2P/indirect/13[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Channel 01/1 : 2[190] -> 7[1e0] via P2P/indirect/6[1d0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Channel 01/1 : 1[180] -> 6[1d0] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Channel 00/1 : 13[1c0] -> 8[170] via P2P/indirect/12[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Channel 00/1 : 8[170] -> 14[1d0] via P2P/indirect/12[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Channel 00/1 : 9[180] -> 15[1e0] via P2P/indirect/11[1a0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Channel 01/1 : 13[1c0] -> 8[170] via P2P/indirect/12[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Channel 00/1 : 1[180] -> 7[1e0] via P2P/indirect/3[1a0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Channel 00/1 : 5[1c0] -> 0[170] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Channel 00/1 : 0[170] -> 6[1d0] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Channel 01/1 : 5[1c0] -> 0[170] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Channel 01/1 : 8[170] -> 14[1d0] via P2P/indirect/12[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Channel 01/1 : 9[180] -> 15[1e0] via P2P/indirect/11[1a0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Channel 01/1 : 1[180] -> 7[1e0] via P2P/indirect/3[1a0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Channel 01/1 : 0[170] -> 6[1d0] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Channel 00/1 : 8[170] -> 15[1e0] via P2P/indirect/12[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Channel 00/1 : 14[1d0] -> 8[170] via P2P/indirect/12[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Channel 01/1 : 8[170] -> 15[1e0] via P2P/indirect/12[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Channel 00/1 : 6[1d0] -> 0[170] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Channel 00/1 : 0[170] -> 7[1e0] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Channel 01/1 : 14[1d0] -> 8[170] via P2P/indirect/12[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Channel 01/1 : 6[1d0] -> 0[170] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Channel 01/1 : 0[170] -> 7[1e0] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Channel 00/1 : 15[1e0] -> 8[170] via P2P/indirect/12[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Channel 01/1 : 15[1e0] -> 8[170] via P2P/indirect/12[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Channel 00/1 : 7[1e0] -> 0[170] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Channel 01/1 : 7[1e0] -> 0[170] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Channel 00/1 : 15[1e0] -> 9[180] via P2P/indirect/13[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Channel 01/1 : 15[1e0] -> 9[180] via P2P/indirect/13[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Channel 00/1 : 7[1e0] -> 1[180] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Channel 01/1 : 7[1e0] -> 1[180] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Channel 00/1 : 14[1d0] -> 9[180] via P2P/indirect/13[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Channel 00/1 : 15[1e0] -> 10[190] via P2P/indirect/11[1a0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Channel 01/1 : 14[1d0] -> 9[180] via P2P/indirect/13[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Channel 00/1 : 6[1d0] -> 1[180] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Channel 01/1 : 15[1e0] -> 10[190] via P2P/indirect/11[1a0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Channel 00/1 : 7[1e0] -> 2[190] via P2P/indirect/3[1a0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Channel 01/1 : 6[1d0] -> 1[180] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Channel 01/1 : 7[1e0] -> 2[190] via P2P/indirect/3[1a0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Channel 00/1 : 13[1c0] -> 10[190] via P2P/indirect/9[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Channel 00/1 : 14[1d0] -> 11[1a0] via P2P/indirect/10[190]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Channel 00/1 : 5[1c0] -> 2[190] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Channel 01/1 : 14[1d0] -> 11[1a0] via P2P/indirect/10[190]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Channel 00/1 : 6[1d0] -> 3[1a0] via P2P/indirect/2[190]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Channel 01/1 : 13[1c0] -> 10[190] via P2P/indirect/9[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Channel 01/1 : 5[1c0] -> 2[190] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Channel 01/1 : 6[1d0] -> 3[1a0] via P2P/indirect/2[190]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Channel 00/1 : 12[1b0] -> 10[190] via P2P/indirect/14[1d0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Channel 00/1 : 13[1c0] -> 11[1a0] via P2P/indirect/9[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Channel 00/1 : 5[1c0] -> 3[1a0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Channel 00/1 : 4[1b0] -> 2[190] via P2P/indirect/6[1d0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Channel 01/1 : 12[1b0] -> 10[190] via P2P/indirect/14[1d0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Channel 01/1 : 5[1c0] -> 3[1a0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Channel 00/1 : 12[1b0] -> 11[1a0] via P2P/indirect/8[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Channel 01/1 : 13[1c0] -> 11[1a0] via P2P/indirect/9[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Channel 01/1 : 4[1b0] -> 2[190] via P2P/indirect/6[1d0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Channel 01/1 : 12[1b0] -> 11[1a0] via P2P/indirect/8[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Channel 00/1 : 4[1b0] -> 3[1a0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Channel 01/1 : 4[1b0] -> 3[1a0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO comm 0x55f14aab6750 rank 12 nranks 16 cudaDev 4 busId 1b0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO comm 0x5655462a42a0 rank 8 nranks 16 cudaDev 0 busId 170 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:NCCL version 2.14.3+cuda11.7\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO comm 0x55d51f024e80 rank 15 nranks 16 cudaDev 7 busId 1e0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO comm 0x560fc87f17b0 rank 11 nranks 16 cudaDev 3 busId 1a0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO comm 0x5567ec238f60 rank 9 nranks 16 cudaDev 1 busId 180 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO comm 0x5623903f5ff0 rank 10 nranks 16 cudaDev 2 busId 190 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO comm 0x565284b825d0 rank 14 nranks 16 cudaDev 6 busId 1d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO comm 0x563d37cdd6a0 rank 13 nranks 16 cudaDev 5 busId 1c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO comm 0x562c60654650 rank 4 nranks 16 cudaDev 4 busId 1b0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO comm 0x55b10f20b030 rank 1 nranks 16 cudaDev 1 busId 180 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO comm 0x562c0ccf9f60 rank 5 nranks 16 cudaDev 5 busId 1c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO comm 0x55c2f3b8df50 rank 0 nranks 16 cudaDev 0 busId 170 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO comm 0x561c8c8915f0 rank 3 nranks 16 cudaDev 3 busId 1a0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO comm 0x55cd51bdc300 rank 2 nranks 16 cudaDev 2 busId 190 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO comm 0x560286848ce0 rank 7 nranks 16 cudaDev 7 busId 1e0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO comm 0x557a7edd2fe0 rank 6 nranks 16 cudaDev 6 busId 1d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Trees [0] 1/-1/-1->2->3 [1] 1/-1/-1->2->3 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] -1/-1/-1->2->6 [5] 6/-1/-1->2->0 [6] 1/-1/-1->2->3 [7] 1/-1/-1->2->3 [8] 3/-1/-1->2->1 [9] 3/-1/-1->2->1 [10] -1/-1/-1->2->6 [11] 6/-1/-1->2->0\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Channel 00/12 :    0   3   2   1   5   6   7   4\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Channel 01/12 :    0   3   2   1   5   6   7   4\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Channel 02/12 :    0   4   7   6   5   1   2   3\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Channel 03/12 :    0   4   7   6   5   1   2   3\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Channel 04/12 :    0   1   3   7   5   4   6   2\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Channel 05/12 :    0   2   6   4   5   7   3   1\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Channel 06/12 :    0   3   2   1   5   6   7   4\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Channel 07/12 :    0   3   2   1   5   6   7   4\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Channel 08/12 :    0   4   7   6   5   1   2   3\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Channel 09/12 :    0   4   7   6   5   1   2   3\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Channel 10/12 :    0   1   3   7   5   4   6   2\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Channel 11/12 :    0   2   6   4   5   7   3   1\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Trees [0] 3/-1/-1->0->-1 [1] 3/-1/-1->0->-1 [2] 4/-1/-1->0->-1 [3] 4/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 3/-1/-1->0->-1 [7] 3/-1/-1->0->-1 [8] 4/-1/-1->0->-1 [9] 4/-1/-1->0->-1 [10] 1/-1/-1->0->-1 [11] 2/-1/-1->0->-1\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Trees [0] 5/-1/-1->1->2 [1] 5/-1/-1->1->2 [2] 2/-1/-1->1->5 [3] 2/-1/-1->1->5 [4] 3/-1/-1->1->0 [5] -1/-1/-1->1->3 [6] 5/-1/-1->1->2 [7] 5/-1/-1->1->2 [8] 2/-1/-1->1->5 [9] 2/-1/-1->1->5 [10] 3/-1/-1->1->0 [11] -1/-1/-1->1->3\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Trees [0] 2/-1/-1->3->0 [1] 2/-1/-1->3->0 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] 7/-1/-1->3->1 [5] 1/-1/-1->3->7 [6] 2/-1/-1->3->0 [7] 2/-1/-1->3->0 [8] -1/-1/-1->3->2 [9] -1/-1/-1->3->2 [10] 7/-1/-1->3->1 [11] 1/-1/-1->3->7\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Trees [0] -1/-1/-1->4->7 [1] -1/-1/-1->4->7 [2] 7/-1/-1->4->0 [3] 7/-1/-1->4->0 [4] 6/-1/-1->4->5 [5] 5/-1/-1->4->6 [6] -1/-1/-1->4->7 [7] -1/-1/-1->4->7 [8] 7/-1/-1->4->0 [9] 7/-1/-1->4->0 [10] 6/-1/-1->4->5 [11] 5/-1/-1->4->6\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Trees [0] 6/-1/-1->5->1 [1] 6/-1/-1->5->1 [2] 1/-1/-1->5->6 [3] 1/-1/-1->5->6 [4] 4/-1/-1->5->7 [5] 7/-1/-1->5->4 [6] 6/-1/-1->5->1 [7] 6/-1/-1->5->1 [8] 1/-1/-1->5->6 [9] 1/-1/-1->5->6 [10] 4/-1/-1->5->7 [11] 7/-1/-1->5->4\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Trees [0] 4/-1/-1->7->6 [1] 4/-1/-1->7->6 [2] 6/-1/-1->7->4 [3] 6/-1/-1->7->4 [4] 5/-1/-1->7->3 [5] 3/-1/-1->7->5 [6] 4/-1/-1->7->6 [7] 4/-1/-1->7->6 [8] 6/-1/-1->7->4 [9] 6/-1/-1->7->4 [10] 5/-1/-1->7->3 [11] 3/-1/-1->7->5\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5 [2] 5/-1/-1->6->7 [3] 5/-1/-1->6->7 [4] 2/-1/-1->6->4 [5] 4/-1/-1->6->2 [6] 7/-1/-1->6->5 [7] 7/-1/-1->6->5 [8] 5/-1/-1->6->7 [9] 5/-1/-1->6->7 [10] 2/-1/-1->6->4 [11] 4/-1/-1->6->2\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Channel 05/0 : 4[1b0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Channel 04/0 : 0[170] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Channel 11/0 : 4[1b0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Channel 10/0 : 0[170] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Channel 00/0 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Channel 02/0 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Channel 01/0 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Channel 03/0 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Channel 02/0 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Channel 00/0 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Channel 06/0 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Channel 08/0 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Channel 03/0 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Channel 01/0 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Channel 07/0 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Channel 09/0 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Channel 08/0 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Channel 06/0 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Channel 09/0 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Channel 07/0 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Channel 04/0 : 4[1b0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Channel 05/0 : 0[170] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Channel 10/0 : 4[1b0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Channel 11/0 : 0[170] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Channel 04/0 : 1[180] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Channel 05/0 : 5[1c0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Channel 10/0 : 1[180] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Channel 11/0 : 5[1c0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Channel 00/0 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Channel 02/0 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Channel 01/0 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Channel 03/0 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Channel 05/0 : 2[190] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Channel 06/0 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Channel 08/0 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Channel 00/0 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Channel 11/0 : 2[190] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Channel 04/0 : 6[1d0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Channel 07/0 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Channel 02/0 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Channel 09/0 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Channel 01/0 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Channel 10/0 : 6[1d0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Channel 03/0 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Channel 06/0 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Channel 08/0 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Channel 07/0 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Trees [0] 4/-1/-1->7->6 [1] 4/-1/-1->7->6 [2] 6/-1/-1->7->4 [3] 6/-1/-1->7->4 [4] 5/-1/-1->7->3 [5] 3/-1/-1->7->5 [6] 4/-1/-1->7->6 [7] 4/-1/-1->7->6 [8] 6/-1/-1->7->4 [9] 6/-1/-1->7->4 [10] 5/-1/-1->7->3 [11] 3/-1/-1->7->5\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Trees [0] 6/-1/-1->5->1 [1] 6/-1/-1->5->1 [2] 1/-1/-1->5->6 [3] 1/-1/-1->5->6 [4] 4/-1/-1->5->7 [5] 7/-1/-1->5->4 [6] 6/-1/-1->5->1 [7] 6/-1/-1->5->1 [8] 1/-1/-1->5->6 [9] 1/-1/-1->5->6 [10] 4/-1/-1->5->7 [11] 7/-1/-1->5->4\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Channel 00/12 :    0   3   2   1   5   6   7   4\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Channel 01/12 :    0   3   2   1   5   6   7   4\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Channel 02/12 :    0   4   7   6   5   1   2   3\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Channel 03/12 :    0   4   7   6   5   1   2   3\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Channel 04/12 :    0   1   3   7   5   4   6   2\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Channel 05/12 :    0   2   6   4   5   7   3   1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Channel 06/12 :    0   3   2   1   5   6   7   4\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Channel 07/12 :    0   3   2   1   5   6   7   4\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Channel 08/12 :    0   4   7   6   5   1   2   3\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Channel 09/12 :    0   4   7   6   5   1   2   3\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Channel 10/12 :    0   1   3   7   5   4   6   2\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Trees [0] 5/-1/-1->1->2 [1] 5/-1/-1->1->2 [2] 2/-1/-1->1->5 [3] 2/-1/-1->1->5 [4] 3/-1/-1->1->0 [5] -1/-1/-1->1->3 [6] 5/-1/-1->1->2 [7] 5/-1/-1->1->2 [8] 2/-1/-1->1->5 [9] 2/-1/-1->1->5 [10] 3/-1/-1->1->0 [11] -1/-1/-1->1->3\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Trees [0] -1/-1/-1->4->7 [1] -1/-1/-1->4->7 [2] 7/-1/-1->4->0 [3] 7/-1/-1->4->0 [4] 6/-1/-1->4->5 [5] 5/-1/-1->4->6 [6] -1/-1/-1->4->7 [7] -1/-1/-1->4->7 [8] 7/-1/-1->4->0 [9] 7/-1/-1->4->0 [10] 6/-1/-1->4->5 [11] 5/-1/-1->4->6\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Trees [0] 1/-1/-1->2->3 [1] 1/-1/-1->2->3 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] -1/-1/-1->2->6 [5] 6/-1/-1->2->0 [6] 1/-1/-1->2->3 [7] 1/-1/-1->2->3 [8] 3/-1/-1->2->1 [9] 3/-1/-1->2->1 [10] -1/-1/-1->2->6 [11] 6/-1/-1->2->0\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Trees [0] 2/-1/-1->3->0 [1] 2/-1/-1->3->0 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] 7/-1/-1->3->1 [5] 1/-1/-1->3->7 [6] 2/-1/-1->3->0 [7] 2/-1/-1->3->0 [8] -1/-1/-1->3->2 [9] -1/-1/-1->3->2 [10] 7/-1/-1->3->1 [11] 1/-1/-1->3->7\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5 [2] 5/-1/-1->6->7 [3] 5/-1/-1->6->7 [4] 2/-1/-1->6->4 [5] 4/-1/-1->6->2 [6] 7/-1/-1->6->5 [7] 7/-1/-1->6->5 [8] 5/-1/-1->6->7 [9] 5/-1/-1->6->7 [10] 2/-1/-1->6->4 [11] 4/-1/-1->6->2\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Channel 11/12 :    0   2   6   4   5   7   3   1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Trees [0] 3/-1/-1->0->-1 [1] 3/-1/-1->0->-1 [2] 4/-1/-1->0->-1 [3] 4/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 3/-1/-1->0->-1 [7] 3/-1/-1->0->-1 [8] 4/-1/-1->0->-1 [9] 4/-1/-1->0->-1 [10] 1/-1/-1->0->-1 [11] 2/-1/-1->0->-1\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Channel 05/0 : 4[1b0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Channel 04/0 : 0[170] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Channel 09/0 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Channel 04/0 : 2[190] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Channel 05/0 : 6[1d0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Channel 10/0 : 2[190] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Channel 11/0 : 6[1d0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Channel 11/0 : 4[1b0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Channel 10/0 : 0[170] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Channel 04/0 : 3[1a0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Channel 05/0 : 7[1e0] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Channel 00/0 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Channel 02/0 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Channel 10/0 : 3[1a0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Channel 11/0 : 7[1e0] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Channel 01/0 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Channel 03/0 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Channel 00/0 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Channel 02/0 : 0[170] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Channel 06/0 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Channel 02/0 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Channel 08/0 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Channel 00/0 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Channel 07/0 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Channel 01/0 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Channel 03/0 : 0[170] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Channel 03/0 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Channel 09/0 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Channel 01/0 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Channel 08/0 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Channel 06/0 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Channel 06/0 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Channel 04/0 : 4[1b0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Channel 08/0 : 0[170] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Channel 02/0 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Channel 00/0 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Channel 09/0 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Channel 07/0 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Channel 10/0 : 4[1b0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Channel 05/0 : 0[170] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Channel 09/0 : 0[170] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Channel 07/0 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Channel 03/0 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Channel 01/0 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Channel 11/0 : 0[170] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Channel 08/0 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Channel 06/0 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Channel 09/0 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Channel 07/0 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Channel 04/0 : 1[180] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Channel 05/0 : 5[1c0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Channel 10/0 : 1[180] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Channel 11/0 : 5[1c0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Channel 04/0 : 7[1e0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Channel 05/0 : 3[1a0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Channel 10/0 : 7[1e0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Channel 11/0 : 3[1a0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Channel 02/0 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Channel 00/0 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Channel 00/0 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Channel 02/0 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Channel 03/0 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Channel 01/0 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Channel 01/0 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Channel 03/0 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Channel 08/0 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Channel 06/0 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Channel 05/0 : 2[190] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Channel 09/0 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Channel 08/0 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Channel 06/0 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Channel 04/0 : 6[1d0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Channel 07/0 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Channel 04/0 : 5[1c0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Channel 11/0 : 2[190] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Channel 02/0 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Channel 05/0 : 1[180] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Channel 00/0 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Channel 00/0 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Channel 09/0 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Channel 02/0 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Channel 10/0 : 5[1c0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Channel 10/0 : 6[1d0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Channel 07/0 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Channel 03/0 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Channel 11/0 : 1[180] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Channel 01/0 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Channel 08/0 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Channel 01/0 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Channel 03/0 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Channel 06/0 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Channel 09/0 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Channel 06/0 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Channel 04/0 : 4[1b0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Channel 07/0 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Channel 10/0 : 4[1b0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Channel 08/0 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Channel 07/0 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Channel 09/0 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Channel 04/0 : 2[190] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Channel 05/0 : 6[1d0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Channel 10/0 : 2[190] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Channel 11/0 : 6[1d0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Channel 05/0 : 7[1e0] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Channel 04/0 : 3[1a0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Channel 00/0 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Channel 11/0 : 7[1e0] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Channel 01/0 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Channel 10/0 : 3[1a0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Channel 02/0 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Channel 06/0 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Channel 00/0 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Channel 02/0 : 0[170] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Channel 03/0 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Channel 07/0 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Channel 08/0 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Channel 09/0 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Channel 01/0 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Channel 02/0 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Channel 03/0 : 0[170] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Channel 00/0 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Channel 03/0 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Channel 01/0 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Channel 05/0 : 4[1b0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Channel 08/0 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Channel 06/0 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Channel 06/0 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Channel 09/0 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Channel 11/0 : 4[1b0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Channel 08/0 : 0[170] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Channel 07/0 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Channel 00/0 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Channel 02/0 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Channel 07/0 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Channel 09/0 : 0[170] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Channel 01/0 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Channel 03/0 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Channel 06/0 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Channel 08/0 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Channel 07/0 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Channel 09/0 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Channel 05/0 : 1[180] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Channel 04/0 : 5[1c0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Channel 11/0 : 1[180] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Channel 10/0 : 5[1c0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Channel 04/0 : 7[1e0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Channel 05/0 : 3[1a0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Channel 10/0 : 7[1e0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Channel 11/0 : 3[1a0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Channel 04/0 : 2[190] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Channel 10/0 : 2[190] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Channel 02/0 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Channel 02/0 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Channel 00/0 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Channel 05/0 : 3[1a0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Channel 03/0 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Channel 00/0 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Channel 01/0 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Channel 11/0 : 3[1a0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Channel 00/0 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Channel 08/0 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Channel 01/0 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Channel 06/0 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Channel 09/0 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Channel 06/0 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Channel 07/0 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Channel 03/0 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Channel 07/0 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Channel 01/0 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Channel 08/0 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Channel 05/0 : 6[1d0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Channel 06/0 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Channel 09/0 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Channel 11/0 : 6[1d0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Channel 07/0 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Channel 04/0 : 5[1c0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Channel 02/0 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Channel 02/0 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Channel 05/0 : 1[180] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Channel 00/0 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Channel 10/0 : 5[1c0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Channel 03/0 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Channel 11/0 : 1[180] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Channel 03/0 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Channel 01/0 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Channel 08/0 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Channel 06/0 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Channel 09/0 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Channel 04/0 : 4[1b0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Channel 04/0 : 7[1e0] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Channel 08/0 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Channel 07/0 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Channel 10/0 : 4[1b0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Channel 05/0 : 2[190] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Channel 09/0 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Channel 04/0 : 6[1d0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Channel 10/0 : 7[1e0] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Channel 11/0 : 2[190] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Channel 10/0 : 6[1d0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Channel 00/0 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Channel 02/0 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Channel 01/0 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Channel 03/0 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Channel 06/0 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Channel 08/0 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Channel 07/0 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Channel 09/0 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Channel 00/0 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Channel 01/0 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Channel 02/0 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Channel 06/0 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Channel 03/0 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Channel 05/0 : 7[1e0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Channel 07/0 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Channel 04/0 : 3[1a0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Channel 08/0 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Channel 11/0 : 7[1e0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Channel 10/0 : 3[1a0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Channel 09/0 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Channel 02/0 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Channel 03/0 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Channel 00/0 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Channel 08/0 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Channel 01/0 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Channel 05/0 : 4[1b0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Channel 09/0 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Channel 06/0 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Channel 11/0 : 4[1b0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Channel 07/0 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Channel 00/0 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Channel 02/0 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Channel 01/0 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Channel 03/0 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Channel 06/0 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Channel 08/0 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Channel 07/0 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Channel 09/0 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Channel 04/0 : 1[180] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Channel 04/0 : 5[1c0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Channel 05/0 : 1[180] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Channel 10/0 : 1[180] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Channel 00/0 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Channel 02/0 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Channel 01/0 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Channel 10/0 : 5[1c0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Channel 11/0 : 1[180] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Channel 03/0 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Channel 05/0 : 5[1c0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Channel 06/0 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Channel 08/0 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Channel 11/0 : 5[1c0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Channel 07/0 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Channel 09/0 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Channel 00/0 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Channel 04/0 : 2[190] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Channel 08/1 : 7[1e0] -> 0[170] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Channel 01/0 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Channel 05/0 : 3[1a0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Channel 10/0 : 2[190] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Channel 08/1 : 3[1a0] -> 4[1b0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Channel 11/0 : 3[1a0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Channel 05/0 : 6[1d0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Channel 06/0 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Channel 00/0 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Channel 02/0 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Channel 11/0 : 6[1d0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Channel 07/0 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Channel 01/0 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Channel 03/0 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Channel 04/1 : 6[1d0] -> 0[170] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Channel 06/0 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Channel 04/1 : 2[190] -> 4[1b0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Channel 08/0 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Channel 09/1 : 7[1e0] -> 0[170] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Channel 09/1 : 3[1a0] -> 4[1b0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Channel 07/0 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Channel 09/0 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Channel 05/0 : 2[190] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Channel 04/0 : 6[1d0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Channel 02/0 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Channel 05/1 : 6[1d0] -> 0[170] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Channel 04/1 : 7[1e0] -> 1[180] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Channel 11/0 : 2[190] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Channel 10/0 : 6[1d0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Channel 04/1 : 3[1a0] -> 5[1c0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Channel 03/0 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Channel 05/1 : 2[190] -> 4[1b0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Channel 04/0 : 7[1e0] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Channel 08/0 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Channel 05/1 : 7[1e0] -> 1[180] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Channel 10/0 : 7[1e0] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Channel 09/0 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Channel 05/1 : 3[1a0] -> 5[1c0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Channel 12/1 : 7[1e0] -> 2[190] via P2P/indirect/3[1a0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Channel 00/0 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Channel 02/0 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Channel 12/1 : 3[1a0] -> 6[1d0] via P2P/indirect/7[1e0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Channel 01/0 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Channel 03/0 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO Channel 13/1 : 7[1e0] -> 2[190] via P2P/indirect/3[1a0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Channel 06/0 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Channel 08/0 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Channel 07/0 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Channel 09/0 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Channel 12/1 : 6[1d0] -> 1[180] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO Channel 13/1 : 3[1a0] -> 6[1d0] via P2P/indirect/7[1e0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Channel 12/1 : 1[180] -> 4[1b0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Channel 12/1 : 2[190] -> 5[1c0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Channel 12/1 : 5[1c0] -> 0[170] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Channel 04/0 : 3[1a0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Channel 13/1 : 6[1d0] -> 1[180] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Channel 05/0 : 7[1e0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Channel 10/0 : 3[1a0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Channel 11/0 : 7[1e0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Channel 13/1 : 1[180] -> 4[1b0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Channel 13/1 : 5[1c0] -> 0[170] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Channel 13/1 : 2[190] -> 5[1c0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Channel 02/0 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Channel 10/1 : 4[1b0] -> 1[180] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Channel 00/0 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Channel 03/0 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Channel 01/0 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Channel 11/1 : 4[1b0] -> 1[180] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Channel 08/0 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Channel 06/0 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Channel 10/1 : 0[170] -> 5[1c0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Channel 09/0 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Channel 07/0 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Channel 04/0 : 1[180] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Channel 05/0 : 5[1c0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Channel 00/0 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Channel 02/0 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Channel 10/0 : 1[180] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Channel 11/1 : 0[170] -> 5[1c0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Channel 11/0 : 5[1c0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Channel 01/0 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Channel 03/0 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Channel 10/1 : 6[1d0] -> 3[1a0] via P2P/indirect/2[190]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Channel 10/1 : 1[180] -> 6[1d0] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Channel 06/0 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Channel 08/0 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO Channel 11/1 : 6[1d0] -> 3[1a0] via P2P/indirect/2[190]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Channel 07/0 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Channel 09/0 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Channel 11/1 : 1[180] -> 6[1d0] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Channel 10/1 : 2[190] -> 7[1e0] via P2P/indirect/6[1d0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Channel 10/1 : 5[1c0] -> 2[190] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO Channel 11/1 : 2[190] -> 7[1e0] via P2P/indirect/6[1d0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Channel 11/1 : 5[1c0] -> 2[190] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Channel 06/1 : 4[1b0] -> 2[190] via P2P/indirect/6[1d0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Channel 08/1 : 7[1e0] -> 0[170] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Channel 06/1 : 1[180] -> 7[1e0] via P2P/indirect/3[1a0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Channel 08/1 : 3[1a0] -> 4[1b0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Channel 07/1 : 4[1b0] -> 2[190] via P2P/indirect/6[1d0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO Channel 07/1 : 1[180] -> 7[1e0] via P2P/indirect/3[1a0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Channel 06/1 : 0[170] -> 6[1d0] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Channel 04/1 : 6[1d0] -> 0[170] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Channel 09/1 : 7[1e0] -> 0[170] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Channel 04/1 : 2[190] -> 4[1b0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Channel 06/1 : 5[1c0] -> 3[1a0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Channel 09/1 : 3[1a0] -> 4[1b0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Channel 04/1 : 7[1e0] -> 1[180] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Channel 05/1 : 6[1d0] -> 0[170] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO Channel 07/1 : 5[1c0] -> 3[1a0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Channel 07/1 : 0[170] -> 6[1d0] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Channel 14/1 : 4[1b0] -> 3[1a0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Channel 05/1 : 2[190] -> 4[1b0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Channel 04/1 : 3[1a0] -> 5[1c0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO Channel 15/1 : 4[1b0] -> 3[1a0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Channel 05/1 : 7[1e0] -> 1[180] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Channel 14/1 : 0[170] -> 7[1e0] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Channel 12/1 : 7[1e0] -> 2[190] via P2P/indirect/3[1a0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Channel 05/1 : 3[1a0] -> 5[1c0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO Channel 15/1 : 0[170] -> 7[1e0] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Channel 12/1 : 3[1a0] -> 6[1d0] via P2P/indirect/7[1e0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO Channel 13/1 : 7[1e0] -> 2[190] via P2P/indirect/3[1a0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Channel 12/1 : 6[1d0] -> 1[180] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Channel 12/1 : 1[180] -> 4[1b0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO Channel 13/1 : 3[1a0] -> 6[1d0] via P2P/indirect/7[1e0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Channel 12/1 : 5[1c0] -> 0[170] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Channel 12/1 : 2[190] -> 5[1c0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Channel 13/1 : 6[1d0] -> 1[180] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Channel 13/1 : 1[180] -> 4[1b0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Channel 13/1 : 5[1c0] -> 0[170] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Channel 10/1 : 4[1b0] -> 1[180] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Channel 13/1 : 2[190] -> 5[1c0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Channel 11/1 : 4[1b0] -> 1[180] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Channel 10/1 : 0[170] -> 5[1c0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Channel 11/1 : 0[170] -> 5[1c0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Channel 10/1 : 6[1d0] -> 3[1a0] via P2P/indirect/2[190]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Channel 10/1 : 1[180] -> 6[1d0] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO Channel 11/1 : 6[1d0] -> 3[1a0] via P2P/indirect/2[190]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Channel 11/1 : 1[180] -> 6[1d0] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Channel 10/1 : 5[1c0] -> 2[190] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Channel 10/1 : 2[190] -> 7[1e0] via P2P/indirect/6[1d0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Channel 11/1 : 5[1c0] -> 2[190] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO Channel 11/1 : 2[190] -> 7[1e0] via P2P/indirect/6[1d0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Channel 06/1 : 4[1b0] -> 2[190] via P2P/indirect/6[1d0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Channel 06/1 : 1[180] -> 7[1e0] via P2P/indirect/3[1a0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Channel 06/1 : 0[170] -> 6[1d0] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Channel 07/1 : 4[1b0] -> 2[190] via P2P/indirect/6[1d0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:207:207 [7] NCCL INFO comm 0x55d51f304ac0 rank 7 nranks 8 cudaDev 7 busId 1e0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:206:206 [1] NCCL INFO comm 0x5567ec52ab50 rank 1 nranks 8 cudaDev 1 busId 180 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Channel 06/1 : 5[1c0] -> 3[1a0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:134:134 [6] NCCL INFO comm 0x565284d5ca80 rank 6 nranks 8 cudaDev 6 busId 1d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Channel 07/1 : 0[170] -> 6[1d0] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:132:132 [2] NCCL INFO comm 0x562391b4e190 rank 2 nranks 8 cudaDev 2 busId 190 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:199:199 [3] NCCL INFO comm 0x560fc9024230 rank 3 nranks 8 cudaDev 3 busId 1a0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:204:204 [5] NCCL INFO comm 0x563d37eb7dc0 rank 5 nranks 8 cudaDev 5 busId 1c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:203:203 [4] NCCL INFO comm 0x55f14ac97d00 rank 4 nranks 8 cudaDev 4 busId 1b0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO Channel 07/1 : 1[180] -> 7[1e0] via P2P/indirect/3[1a0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:595:595 [0] NCCL INFO comm 0x56554649a440 rank 0 nranks 8 cudaDev 0 busId 170 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO Channel 07/1 : 5[1c0] -> 3[1a0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Channel 14/1 : 0[170] -> 7[1e0] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Channel 14/1 : 4[1b0] -> 3[1a0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO Channel 15/1 : 4[1b0] -> 3[1a0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO Channel 15/1 : 0[170] -> 7[1e0] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:198:198 [1] NCCL INFO comm 0x55b10fac2b00 rank 1 nranks 8 cudaDev 1 busId 180 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:271:271 [5] NCCL INFO comm 0x562c0cd82cf0 rank 5 nranks 8 cudaDev 5 busId 1c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:265:265 [6] NCCL INFO comm 0x557a7efade40 rank 6 nranks 8 cudaDev 6 busId 1d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:200:200 [4] NCCL INFO comm 0x562c60e0eca0 rank 4 nranks 8 cudaDev 4 busId 1b0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:659:659 [0] NCCL INFO comm 0x55c2f50a2240 rank 0 nranks 8 cudaDev 0 busId 170 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Running smdistributed.dataparallel v1.7.0[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:SMDDP: Multi node\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:ENA mode\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:270:270 [3] NCCL INFO comm 0x561c8d21da00 rank 3 nranks 8 cudaDev 3 busId 1a0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:268:268 [7] NCCL INFO comm 0x560288d134d0 rank 7 nranks 8 cudaDev 7 busId 1e0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:196:196 [2] NCCL INFO comm 0x55cd5206cf10 rank 2 nranks 8 cudaDev 2 busId 190 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:2023-10-27 01:58:20,147 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:1 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:2023-10-27 01:58:20,147 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:1 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:2023-10-27 01:58:20,147 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:1 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:2023-10-27 01:58:20,147 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:1 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:2023-10-27 01:58:20,147 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:1 to store for rank: 10\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:2023-10-27 01:58:20,147 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:1 to store for rank: 9\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:2023-10-27 01:58:20,147 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:1 to store for rank: 8\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:2023-10-27 01:58:20,147 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:1 to store for rank: 11\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:2023-10-27 01:58:21,146 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:1 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:2023-10-27 01:58:21,146 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:1 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:2023-10-27 01:58:21,146 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:1 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:2023-10-27 01:58:21,146 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:1 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:2023-10-27 01:58:21,146 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:1 to store for rank: 12\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:2023-10-27 01:58:21,147 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:1 to store for rank: 13\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:2023-10-27 01:58:21,147 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:1 to store for rank: 14\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:2023-10-27 01:58:21,147 - torch.distributed.distributed_c10d - INFO - Rank 12: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:2023-10-27 01:58:21,147 - torch.distributed.distributed_c10d - INFO - Added key: store_based_barrier_key:1 to store for rank: 15\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:2023-10-27 01:58:21,147 - torch.distributed.distributed_c10d - INFO - Rank 13: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:2023-10-27 01:58:21,147 - torch.distributed.distributed_c10d - INFO - Rank 14: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:2023-10-27 01:58:21,147 - torch.distributed.distributed_c10d - INFO - Rank 15: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:2023-10-27 01:58:21,152 - torch.distributed.distributed_c10d - INFO - Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:2023-10-27 01:58:21,152 - torch.distributed.distributed_c10d - INFO - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:2023-10-27 01:58:21,152 - torch.distributed.distributed_c10d - INFO - Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:2023-10-27 01:58:21,152 - torch.distributed.distributed_c10d - INFO - Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:2023-10-27 01:58:21,152 - torch.distributed.distributed_c10d - INFO - Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:2023-10-27 01:58:21,153 - torch.distributed.distributed_c10d - INFO - Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:2023-10-27 01:58:21,153 - torch.distributed.distributed_c10d - INFO - Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:2023-10-27 01:58:21,154 - torch.distributed.distributed_c10d - INFO - Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:2023-10-27 01:58:21,156 - torch.distributed.distributed_c10d - INFO - Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:2023-10-27 01:58:21,156 - torch.distributed.distributed_c10d - INFO - Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:2023-10-27 01:58:21,157 - torch.distributed.distributed_c10d - INFO - Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:2023-10-27 01:58:21,157 - torch.distributed.distributed_c10d - INFO - Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:  warnings.warn(\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:  warnings.warn(\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:  warnings.warn(\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:  warnings.warn(\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:  warnings.warn(\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:  warnings.warn(\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:  warnings.warn(\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:  warnings.warn(\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:  warnings.warn(\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:  warnings.warn(\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:  warnings.warn(\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:  warnings.warn(\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:  warnings.warn(\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: str_labels, text. If str_labels, text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: str_labels, text. If str_labels, text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:  warnings.warn(\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:  warnings.warn(\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:  warnings.warn(\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:***** Running training *****\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:  Num examples = 12848\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:  Num Epochs = 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:  Instantaneous batch size per device = 32\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:  Total train batch size (w. parallel, distributed & accumulation) = 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:***** Running training *****\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:  Num examples = 12848\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:  Num Epochs = 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:  Instantaneous batch size per device = 32\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:  Total train batch size (w. parallel, distributed & accumulation) = 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:  Gradient Accumulation steps = 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:  Gradient Accumulation steps = 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:  Total optimization steps = 78\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:  Total optimization steps = 78\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:  Number of trainable parameters = 66958086\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:  Number of trainable parameters = 66958086\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015  0%|          | 0/78 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2023-10-27 01:58:21.563: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.26.0 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2023-10-27 01:58:21.563: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.26.0 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2023-10-27 01:58:21.563: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.26.0 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2023-10-27 01:58:21.564: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.26.0 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-10-27 01:58:21.565: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.26.0 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2023-10-27 01:58:21.566: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.26.0 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2023-10-27 01:58:21.567: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.26.0 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2023-10-27 01:58:21.568: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.26.0 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:2023-10-27 01:58:21,569 - root - INFO - Using NamedTuple = typing._NamedTuple instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:2023-10-27 01:58:21,569 - root - INFO - Using NamedTuple = typing._NamedTuple instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:2023-10-27 01:58:21,569 - root - INFO - Using NamedTuple = typing._NamedTuple instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:2023-10-27 01:58:21,569 - root - INFO - Using NamedTuple = typing._NamedTuple instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:2023-10-27 01:58:21,571 - root - INFO - Using NamedTuple = typing._NamedTuple instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:2023-10-27 01:58:21,572 - root - INFO - Using NamedTuple = typing._NamedTuple instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:2023-10-27 01:58:21,573 - root - INFO - Using NamedTuple = typing._NamedTuple instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:2023-10-27 01:58:21,574 - root - INFO - Using NamedTuple = typing._NamedTuple instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:[2023-10-27 01:58:21.574: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.26.0 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:[2023-10-27 01:58:21.574: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.26.0 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:[2023-10-27 01:58:21.574: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.26.0 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:[2023-10-27 01:58:21.574: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.26.0 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:[2023-10-27 01:58:21.574: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.26.0 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:2023-10-27 01:58:21,580 - root - INFO - Using NamedTuple = typing._NamedTuple instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:2023-10-27 01:58:21,580 - root - INFO - Using NamedTuple = typing._NamedTuple instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:2023-10-27 01:58:21,580 - root - INFO - Using NamedTuple = typing._NamedTuple instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:2023-10-27 01:58:21,580 - root - INFO - Using NamedTuple = typing._NamedTuple instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:2023-10-27 01:58:21,580 - root - INFO - Using NamedTuple = typing._NamedTuple instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:[2023-10-27 01:58:21.584: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.26.0 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:2023-10-27 01:58:21,591 - root - INFO - Using NamedTuple = typing._NamedTuple instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2023-10-27 01:58:21.606 algo-1:271 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2023-10-27 01:58:21.606 algo-1:268 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2023-10-27 01:58:21.606 algo-1:198 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2023-10-27 01:58:21.606 algo-1:270 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-10-27 01:58:21.607 algo-1:659 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2023-10-27 01:58:21.610 algo-1:265 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2023-10-27 01:58:21.610 algo-1:200 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2023-10-27 01:58:21.611 algo-1:196 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:[2023-10-27 01:58:21.617 algo-2:206 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:[2023-10-27 01:58:21.618 algo-2:134 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:[2023-10-27 01:58:21.618 algo-2:203 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:[2023-10-27 01:58:21.618 algo-2:132 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:[2023-10-27 01:58:21.618 algo-2:204 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:[2023-10-27 01:58:21.626: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.26.0 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:[2023-10-27 01:58:21.627: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.26.0 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:[2023-10-27 01:58:21.629 algo-2:207 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:2023-10-27 01:58:21,632 - root - INFO - Using NamedTuple = typing._NamedTuple instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:2023-10-27 01:58:21,634 - root - INFO - Using NamedTuple = typing._NamedTuple instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-10-27 01:58:21.652 algo-1:659 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2023-10-27 01:58:21.652 algo-1:268 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2023-10-27 01:58:21.652 algo-1:271 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2023-10-27 01:58:21.652 algo-1:198 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2023-10-27 01:58:21.652 algo-1:270 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2023-10-27 01:58:21.653 algo-1:200 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2023-10-27 01:58:21.653 algo-1:198 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-10-27 01:58:21.653 algo-1:659 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2023-10-27 01:58:21.653 algo-1:268 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2023-10-27 01:58:21.653 algo-1:271 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2023-10-27 01:58:21.653 algo-1:270 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2023-10-27 01:58:21.653 algo-1:271 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2023-10-27 01:58:21.653 algo-1:198 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-10-27 01:58:21.653 algo-1:659 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2023-10-27 01:58:21.653 algo-1:268 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2023-10-27 01:58:21.653 algo-1:270 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2023-10-27 01:58:21.653 algo-1:200 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2023-10-27 01:58:21.654 algo-1:200 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2023-10-27 01:58:21.654 algo-1:265 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-10-27 01:58:21.654 algo-1:659 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2023-10-27 01:58:21.654 algo-1:268 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-10-27 01:58:21.654 algo-1:659 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2023-10-27 01:58:21.654 algo-1:268 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2023-10-27 01:58:21.654 algo-1:271 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2023-10-27 01:58:21.654 algo-1:198 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2023-10-27 01:58:21.654 algo-1:271 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2023-10-27 01:58:21.654 algo-1:270 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2023-10-27 01:58:21.654 algo-1:198 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2023-10-27 01:58:21.654 algo-1:270 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2023-10-27 01:58:21.654 algo-1:200 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2023-10-27 01:58:21.654 algo-1:200 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2023-10-27 01:58:21.655 algo-1:265 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2023-10-27 01:58:21.655 algo-1:265 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2023-10-27 01:58:21.656 algo-1:265 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2023-10-27 01:58:21.656 algo-1:265 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2023-10-27 01:58:21.656 algo-1:196 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2023-10-27 01:58:21.657 algo-1:196 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2023-10-27 01:58:21.657 algo-1:196 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2023-10-27 01:58:21.658 algo-1:196 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2023-10-27 01:58:21.658 algo-1:196 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:[2023-10-27 01:58:21.662 algo-2:206 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:[2023-10-27 01:58:21.662 algo-2:134 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:[2023-10-27 01:58:21.662 algo-2:132 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:[2023-10-27 01:58:21.662 algo-2:203 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:[2023-10-27 01:58:21.662 algo-2:206 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:[2023-10-27 01:58:21.662 algo-2:204 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:[2023-10-27 01:58:21.662 algo-2:134 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:[2023-10-27 01:58:21.663 algo-2:132 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:[2023-10-27 01:58:21.663 algo-2:206 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:[2023-10-27 01:58:21.663 algo-2:203 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:[2023-10-27 01:58:21.663 algo-2:134 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:[2023-10-27 01:58:21.663 algo-2:204 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:[2023-10-27 01:58:21.663 algo-2:132 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:[2023-10-27 01:58:21.663 algo-2:203 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:[2023-10-27 01:58:21.663 algo-2:206 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:[2023-10-27 01:58:21.663 algo-2:206 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:[2023-10-27 01:58:21.663 algo-2:204 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:[2023-10-27 01:58:21.663 algo-2:134 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:[2023-10-27 01:58:21.664 algo-2:132 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:[2023-10-27 01:58:21.664 algo-2:134 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:[2023-10-27 01:58:21.664 algo-2:132 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:[2023-10-27 01:58:21.664 algo-2:203 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:[2023-10-27 01:58:21.664 algo-2:203 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:[2023-10-27 01:58:21.664 algo-2:204 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:[2023-10-27 01:58:21.664 algo-2:204 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:[2023-10-27 01:58:21.670 algo-2:595 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:[2023-10-27 01:58:21.674 algo-2:207 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:[2023-10-27 01:58:21.675 algo-2:207 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:[2023-10-27 01:58:21.675 algo-2:207 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:[2023-10-27 01:58:21.676 algo-2:199 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:[2023-10-27 01:58:21.676 algo-2:207 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:[2023-10-27 01:58:21.676 algo-2:207 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:[2023-10-27 01:58:21.716 algo-2:595 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:[2023-10-27 01:58:21.716 algo-2:595 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:[2023-10-27 01:58:21.717 algo-2:595 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:[2023-10-27 01:58:21.718 algo-2:595 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:[2023-10-27 01:58:21.718 algo-2:595 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:[2023-10-27 01:58:21.727 algo-2:199 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:[2023-10-27 01:58:21.728 algo-2:199 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:[2023-10-27 01:58:21.728 algo-2:199 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:[2023-10-27 01:58:21.729 algo-2:199 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:[2023-10-27 01:58:21.729 algo-2:199 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015  1%|▏         | 1/78 [00:02<02:38,  2.06s/it]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:2023-10-27 01:58:23,545 - torch.nn.parallel.distributed - INFO - Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:2023-10-27 01:58:23,545 - torch.nn.parallel.distributed - INFO - Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:2023-10-27 01:58:23,545 - torch.nn.parallel.distributed - INFO - Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:2023-10-27 01:58:23,545 - torch.nn.parallel.distributed - INFO - Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:2023-10-27 01:58:23,545 - torch.nn.parallel.distributed - INFO - Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:2023-10-27 01:58:23,545 - torch.nn.parallel.distributed - INFO - Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:2023-10-27 01:58:23,545 - torch.nn.parallel.distributed - INFO - Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:2023-10-27 01:58:23,545 - torch.nn.parallel.distributed - INFO - Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:2023-10-27 01:58:23,547 - torch.nn.parallel.distributed - INFO - Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:2023-10-27 01:58:23,547 - torch.nn.parallel.distributed - INFO - Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:2023-10-27 01:58:23,547 - torch.nn.parallel.distributed - INFO - Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:2023-10-27 01:58:23,547 - torch.nn.parallel.distributed - INFO - Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:2023-10-27 01:58:23,547 - torch.nn.parallel.distributed - INFO - Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:2023-10-27 01:58:23,547 - torch.nn.parallel.distributed - INFO - Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:2023-10-27 01:58:23,547 - torch.nn.parallel.distributed - INFO - Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:2023-10-27 01:58:23,547 - torch.nn.parallel.distributed - INFO - Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015  3%|▎         | 2/78 [00:02<01:41,  1.34s/it]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015  4%|▍         | 3/78 [00:03<01:13,  1.02it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015  5%|▌         | 4/78 [00:04<01:00,  1.22it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015  6%|▋         | 5/78 [00:04<00:52,  1.38it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015  8%|▊         | 6/78 [00:05<00:48,  1.48it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015  9%|▉         | 7/78 [00:05<00:45,  1.55it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 10%|█         | 8/78 [00:06<00:43,  1.60it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 12%|█▏        | 9/78 [00:06<00:42,  1.63it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 13%|█▎        | 10/78 [00:07<00:40,  1.66it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 14%|█▍        | 11/78 [00:08<00:39,  1.70it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 15%|█▌        | 12/78 [00:08<00:38,  1.71it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 17%|█▋        | 13/78 [00:09<00:37,  1.73it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 18%|█▊        | 14/78 [00:09<00:36,  1.75it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 19%|█▉        | 15/78 [00:10<00:35,  1.76it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 21%|██        | 16/78 [00:10<00:35,  1.75it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 22%|██▏       | 17/78 [00:11<00:35,  1.74it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 23%|██▎       | 18/78 [00:12<00:34,  1.75it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 24%|██▍       | 19/78 [00:12<00:33,  1.77it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 26%|██▌       | 20/78 [00:13<00:32,  1.77it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 27%|██▋       | 21/78 [00:13<00:31,  1.78it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 28%|██▊       | 22/78 [00:14<00:31,  1.79it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 29%|██▉       | 23/78 [00:14<00:31,  1.77it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 31%|███       | 24/78 [00:15<00:30,  1.78it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 32%|███▏      | 25/78 [00:15<00:30,  1.77it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 33%|███▎      | 26/78 [00:16<00:24,  2.12it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:{'loss': 0.6805, 'learning_rate': 1.5599999999999999e-06, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 33%|███▎      | 26/78 [00:16<00:24,  2.12it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: str_labels, text. If str_labels, text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: str_labels, text. If str_labels, text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:  Num examples = 3212\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:  Batch size = 64\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:  Num examples = 3212\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:  Batch size = 64\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015  0%|          | 0/4 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 50%|█████     | 2/4 [00:00<00:00,  5.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 75%|███████▌  | 3/4 [00:00<00:00,  4.27it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015100%|██████████| 4/4 [00:00<00:00,  3.73it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015                                               #015\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:{'eval_loss': 0.6709368228912354, 'eval_f1': 0.24830938292476754, 'eval_roc_auc': 0.5248443337484434, 'eval_accuracy': 0.04234122042341221, 'eval_runtime': 1.3599, 'eval_samples_per_second': 2362.004, 'eval_steps_per_second': 2.941, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 33%|███▎      | 26/78 [00:17<00:24,  2.12it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015100%|██████████| 4/4 [00:01<00:00,  3.73it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015                                             #033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 35%|███▍      | 27/78 [00:18<00:46,  1.09it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 36%|███▌      | 28/78 [00:18<00:40,  1.24it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 37%|███▋      | 29/78 [00:19<00:35,  1.36it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 38%|███▊      | 30/78 [00:19<00:32,  1.47it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 40%|███▉      | 31/78 [00:20<00:30,  1.56it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 41%|████      | 32/78 [00:20<00:28,  1.62it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 42%|████▏     | 33/78 [00:21<00:26,  1.67it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 44%|████▎     | 34/78 [00:22<00:25,  1.71it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 45%|████▍     | 35/78 [00:22<00:24,  1.73it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 46%|████▌     | 36/78 [00:23<00:24,  1.73it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 47%|████▋     | 37/78 [00:23<00:23,  1.73it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 49%|████▊     | 38/78 [00:24<00:23,  1.72it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 50%|█████     | 39/78 [00:24<00:22,  1.73it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 51%|█████▏    | 40/78 [00:25<00:21,  1.75it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 53%|█████▎    | 41/78 [00:26<00:21,  1.76it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 54%|█████▍    | 42/78 [00:26<00:20,  1.77it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 55%|█████▌    | 43/78 [00:27<00:19,  1.76it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 56%|█████▋    | 44/78 [00:27<00:19,  1.77it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 58%|█████▊    | 45/78 [00:28<00:18,  1.76it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 59%|█████▉    | 46/78 [00:28<00:18,  1.77it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 60%|██████    | 47/78 [00:29<00:17,  1.78it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 62%|██████▏   | 48/78 [00:29<00:16,  1.78it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 63%|██████▎   | 49/78 [00:30<00:16,  1.78it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 64%|██████▍   | 50/78 [00:31<00:15,  1.79it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 65%|██████▌   | 51/78 [00:31<00:15,  1.79it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 67%|██████▋   | 52/78 [00:31<00:12,  2.16it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:{'loss': 0.6524, 'learning_rate': 3.1199999999999998e-06, 'epoch': 2.0}\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 67%|██████▋   | 52/78 [00:31<00:12,  2.16it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: str_labels, text. If str_labels, text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: str_labels, text. If str_labels, text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:  Num examples = 3212\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:  Batch size = 64\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:  Num examples = 3212\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:  Batch size = 64\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015  0%|          | 0/4 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 50%|█████     | 2/4 [00:00<00:00,  6.17it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 75%|███████▌  | 3/4 [00:00<00:00,  4.35it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015100%|██████████| 4/4 [00:00<00:00,  3.78it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015                                               #015\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015                                             [1,mpirank:0,algo-1]<stderr>:#015#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:{'eval_loss': 0.6181860566139221, 'eval_f1': 0.20248138957816378, 'eval_roc_auc': 0.5507471980074721, 'eval_accuracy': 0.12391033623910336, 'eval_runtime': 1.3094, 'eval_samples_per_second': 2453.063, 'eval_steps_per_second': 3.055, 'epoch': 2.0}\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 67%|██████▋   | 52/78 [00:33<00:12,  2.16it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015100%|██████████| 4/4 [00:00<00:00,  3.78it/s]#033[A[1,mpirank:0,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015                                             #033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 68%|██████▊   | 53/78 [00:33<00:22,  1.12it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 69%|██████▉   | 54/78 [00:34<00:18,  1.27it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 71%|███████   | 55/78 [00:34<00:16,  1.39it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 72%|███████▏  | 56/78 [00:35<00:14,  1.49it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 73%|███████▎  | 57/78 [00:36<00:13,  1.55it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 74%|███████▍  | 58/78 [00:36<00:12,  1.60it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 76%|███████▌  | 59/78 [00:37<00:11,  1.66it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 77%|███████▋  | 60/78 [00:37<00:10,  1.69it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 78%|███████▊  | 61/78 [00:38<00:09,  1.72it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 79%|███████▉  | 62/78 [00:38<00:09,  1.72it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 81%|████████  | 63/78 [00:39<00:08,  1.72it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 82%|████████▏ | 64/78 [00:40<00:08,  1.72it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 83%|████████▎ | 65/78 [00:40<00:07,  1.71it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 85%|████████▍ | 66/78 [00:41<00:06,  1.73it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 86%|████████▌ | 67/78 [00:41<00:06,  1.73it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 87%|████████▋ | 68/78 [00:42<00:05,  1.73it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 88%|████████▊ | 69/78 [00:42<00:05,  1.73it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 90%|████████▉ | 70/78 [00:43<00:04,  1.74it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 91%|█████████ | 71/78 [00:44<00:04,  1.73it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 92%|█████████▏| 72/78 [00:44<00:03,  1.73it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 94%|█████████▎| 73/78 [00:45<00:02,  1.73it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 95%|█████████▍| 74/78 [00:45<00:02,  1.63it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 96%|█████████▌| 75/78 [00:46<00:01,  1.65it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 97%|█████████▋| 76/78 [00:47<00:01,  1.67it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 99%|█████████▊| 77/78 [00:47<00:00,  1.68it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015100%|██████████| 78/78 [00:47<00:00,  2.02it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:{'loss': 0.5677, 'learning_rate': 4.68e-06, 'epoch': 3.0}\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015100%|██████████| 78/78 [00:47<00:00,  2.02it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: str_labels, text. If str_labels, text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: str_labels, text. If str_labels, text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:  Num examples = 3212\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:  Batch size = 64\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:  Num examples = 3212\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:  Batch size = 64\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015  0%|          | 0/4 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 50%|█████     | 2/4 [00:00<00:00,  6.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 75%|███████▌  | 3/4 [00:00<00:00,  4.30it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015100%|██████████| 4/4 [00:00<00:00,  3.73it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015                                               #015\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015                                             #015#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:{'eval_loss': 0.5066025257110596, 'eval_f1': 0.003108486167236556, 'eval_roc_auc': 0.5007783312577833, 'eval_accuracy': 0.001556662515566625, 'eval_runtime': 1.3378, 'eval_samples_per_second': 2400.878, 'eval_steps_per_second': 2.99, 'epoch': 3.0}\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015100%|██████████| 78/78 [00:49<00:00,  2.02it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015100%|██████████| 4/4 [00:00<00:00,  3.73it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015                                             #033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:Training completed. Do not forget to share your model on huggingface.co/models =)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Training completed. Do not forget to share your model on huggingface.co/models =)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:{'train_runtime': 49.2997, 'train_samples_per_second': 781.83, 'train_steps_per_second': 1.582, 'train_loss': 0.6335140619522486, 'epoch': 3.0}\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015100%|██████████| 78/78 [00:49<00:00,  2.02it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015100%|██████████| 78/78 [00:49<00:00,  1.58it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: str_labels, text. If str_labels, text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: str_labels, text. If str_labels, text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:  Num examples = 3212\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:  Num examples = 3212\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:  Batch size = 64\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:  Batch size = 64\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015  0%|          | 0/4 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 50%|█████     | 2/4 [00:00<00:00,  6.08it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 75%|███████▌  | 3/4 [00:00<00:00,  4.21it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015100%|██████████| 4/4 [00:01<00:00,  3.63it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:***** Eval results *****\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015100%|██████████| 4/4 [00:01<00:00,  3.92it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:***** Eval results *****\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:***** Eval results *****\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:***** Eval results *****\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:***** Eval results *****\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:Saving model checkpoint to /opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Saving model checkpoint to /opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:***** Eval results *****\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:***** Eval results *****\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Configuration saved in /opt/ml/model/config.json\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:Configuration saved in /opt/ml/model/config.json\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:***** Eval results *****\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:***** Eval results *****\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:***** Eval results *****\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:***** Eval results *****\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:***** Eval results *****\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:***** Eval results *****\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:***** Eval results *****\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:***** Eval results *****\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:***** Eval results *****\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:Model weights saved in /opt/ml/model/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Model weights saved in /opt/ml/model/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:tokenizer config file saved in /opt/ml/model/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:tokenizer config file saved in /opt/ml/model/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:Special tokens file saved in /opt/ml/model/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Special tokens file saved in /opt/ml/model/special_tokens_map.json\u001b[0m\n",
      "\u001b[35m2023-10-27 01:59:21,741 sagemaker-training-toolkit INFO     Invoked on_terminate from psutil.wait_for_procs\u001b[0m\n",
      "\u001b[35m2023-10-27 01:59:21,741 sagemaker-training-toolkit INFO     process psutil.Process(pid=58, name='orted', status='terminated', started='01:58:04') terminated with exit code None\u001b[0m\n",
      "\u001b[35m2023-10-27 01:59:21,741 sagemaker-training-toolkit INFO     Reporting status for ORTEd process. gone: [psutil.Process(pid=58, name='orted', status='terminated', started='01:58:04')] alive: []\u001b[0m\n",
      "\u001b[35m2023-10-27 01:59:21,741 sagemaker-training-toolkit INFO     Orted process exited\u001b[0m\n",
      "\u001b[34m2023-10-27 01:59:21,706 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-10-27 01:59:21,706 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-10-27 01:59:21,707 sagemaker-training-toolkit INFO     Begin writing status file from leader node to worker nodes\u001b[0m\n",
      "\u001b[34m2023-10-27 01:59:21,707 sagemaker-training-toolkit INFO     Start writing mpirun finished status to algo-2\u001b[0m\n",
      "\u001b[34m2023-10-27 01:59:21,864 sagemaker-training-toolkit INFO     output from subprocess run CompletedProcess(args=['ssh', 'algo-2', 'touch', '/tmp/done.algo-1'], returncode=0, stdout='', stderr='')\u001b[0m\n",
      "\u001b[34m2023-10-27 01:59:21,865 sagemaker-training-toolkit INFO     Finished writing status file\u001b[0m\n",
      "\u001b[34m2023-10-27 01:59:51,886 sagemaker-training-toolkit INFO     Finished writing status file from leader node to worker nodes\u001b[0m\n",
      "\u001b[34m2023-10-27 01:59:51,887 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\u001b[35m2023-10-27 01:59:51,772 sagemaker-training-toolkit INFO     Begin looking for status file on algo-2\u001b[0m\n",
      "\u001b[35m2023-10-27 01:59:51,772 sagemaker-training-toolkit INFO     MPI training job status file found. Exit gracefully\u001b[0m\n",
      "\u001b[35m2023-10-27 01:59:51,772 sagemaker-training-toolkit INFO     End looking for status file\u001b[0m\n",
      "\u001b[35m2023-10-27 01:59:51,772 sagemaker-training-toolkit INFO     MPI process finished.\u001b[0m\n",
      "\u001b[35m2023-10-27 01:59:51,772 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-10-27 02:00:14 Uploading - Uploading generated training model\n",
      "2023-10-27 02:00:14 Completed - Training job completed\n",
      "Training seconds: 958\n",
      "Billable seconds: 958\n"
     ]
    }
   ],
   "source": [
    "# starting the train job with our uploaded datasets as input\n",
    "huggingface_estimator.fit({'train': training_input_path, 'test': test_input_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying the endpoint\n",
    "\n",
    "To deploy our endpoint, we call `deploy()` on our HuggingFace estimator object, passing in our desired number of instances and instance type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: huggingface-pytorch-training-2023-10-27-02-11-31-771\n",
      "INFO:sagemaker:Creating endpoint-config with name huggingface-pytorch-training-2023-10-27-02-11-31-771\n",
      "INFO:sagemaker:Creating endpoint with name huggingface-pytorch-training-2023-10-27-02-11-31-771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "predictor = huggingface_estimator.deploy(1, \"ml.g4dn.xlarge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we use the returned predictor object to call the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'casual', 'score': 0.4718174338340759}]\n",
      "[{'label': 'casual', 'score': 0.44566860795021057}]\n"
     ]
    }
   ],
   "source": [
    "happy_input = {\"inputs\": \"Good morning how are you today?\"}\n",
    "black_eye_pea_lyrics = {\"inputs\": \"Overseas, yeah, we tryna stop terrorism but we still got terrorists here livin' in the USA, the big CIA The Bloods and the Crips and the KKK\"}\n",
    "\n",
    "print(predictor.predict(happy_input))\n",
    "print(predictor.predict(black_eye_pea_lyrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we delete the endpoint again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting model with name: huggingface-pytorch-training-2023-10-24-20-23-04-575\n",
      "INFO:sagemaker:Deleting endpoint configuration with name: huggingface-pytorch-training-2023-10-24-20-23-04-575\n",
      "INFO:sagemaker:Deleting endpoint with name: huggingface-pytorch-training-2023-10-24-20-23-04-575\n"
     ]
    }
   ],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimator Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "container image used for training job: \n",
      "None\n",
      "\n",
      "s3 uri where the trained model is located: \n",
      "s3://sagemaker-us-east-2-391015568214/huggingface-pytorch-training-2023-10-25-06-39-03-508/output/model.tar.gz\n",
      "\n",
      "latest training job name for this estimator: \n",
      "huggingface-pytorch-training-2023-10-25-06-39-03-508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# container image used for training job\n",
    "print(f\"container image used for training job: \\n{huggingface_estimator.image_uri}\\n\")\n",
    "\n",
    "# s3 uri where the trained model is located\n",
    "print(f\"s3 uri where the trained model is located: \\n{huggingface_estimator.model_data}\\n\")\n",
    "\n",
    "# latest training job name for this estimator\n",
    "print(f\"latest training job name for this estimator: \\n{huggingface_estimator.latest_training_job.name}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-25 06:52:03 Starting - Preparing the instances for training\n",
      "2023-10-25 06:52:03 Downloading - Downloading input data\n",
      "2023-10-25 06:52:03 Training - Training image download completed. Training in progress.\n",
      "2023-10-25 06:52:03 Uploading - Uploading generated training model\n",
      "2023-10-25 06:52:03 Completed - Training job completed\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-10-25 06:47:43,564 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-10-25 06:47:43,585 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-10-25 06:47:43,598 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-10-25 06:47:43,601 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-10-25 06:47:43,891 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-10-25 06:47:43,928 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-10-25 06:47:43,967 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-10-25 06:47:43,982 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 1,\n",
      "        \"model_name\": \"distilbert-base-uncased\",\n",
      "        \"train_batch_size\": 32\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.p3.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"huggingface-pytorch-training-2023-10-25-06-39-03-508\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-391015568214/huggingface-pytorch-training-2023-10-25-06-39-03-508/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_multiclass\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_multiclass.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":1,\"model_name\":\"distilbert-base-uncased\",\"train_batch_size\":32}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_multiclass.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.p3.2xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_multiclass\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-391015568214/huggingface-pytorch-training-2023-10-25-06-39-03-508/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.p3.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":1,\"model_name\":\"distilbert-base-uncased\",\"train_batch_size\":32},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"huggingface-pytorch-training-2023-10-25-06-39-03-508\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-391015568214/huggingface-pytorch-training-2023-10-25-06-39-03-508/source/sourcedir.tar.gz\",\"module_name\":\"train_multiclass\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_multiclass.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"1\",\"--model_name\",\"distilbert-base-uncased\",\"--train_batch_size\",\"32\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=1\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_NAME=distilbert-base-uncased\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_BATCH_SIZE=32\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python39.zip:/opt/conda/lib/python3.9:/opt/conda/lib/python3.9/lib-dynload:/opt/conda/lib/python3.9/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.9 train_multiclass.py --epochs 1 --model_name distilbert-base-uncased --train_batch_size 32\u001b[0m\n",
      "\u001b[34m[2023-10-25 06:47:46.172: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.26.0 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34m2023-10-25 06:47:46,179 root         INFO     Using NamedTuple = typing._NamedTuple instead.\u001b[0m\n",
      "\u001b[34m2023-10-25 06:47:46,211 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34m2023-10-25 06:47:49,671 - __main__ - INFO -  loaded train_dataset length is: 12797\u001b[0m\n",
      "\u001b[34m2023-10-25 06:47:49,671 - __main__ - INFO -  loaded test_dataset length is: 3200\u001b[0m\n",
      "\u001b[34mDownloading (…)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)lve/main/config.json: 100%|██████████| 483/483 [00:00<00:00, 60.3kB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/268M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  16%|█▌        | 41.9M/268M [00:00<00:00, 338MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  35%|███▌      | 94.4M/268M [00:00<00:00, 396MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  55%|█████▍    | 147M/268M [00:00<00:00, 413MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  70%|███████   | 189M/268M [00:00<00:00, 415MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  90%|█████████ | 241M/268M [00:00<00:00, 418MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";: 100%|██████████| 268M/268M [00:00<00:00, 407MB/s]\u001b[0m\n",
      "\u001b[34mSome weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\u001b[0m\n",
      "\u001b[34m- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34mSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34mSome weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\u001b[0m\n",
      "\u001b[34m- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34mSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34mDownloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)okenizer_config.json: 100%|██████████| 28.0/28.0 [00:00<00:00, 9.64kB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)solve/main/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 10.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)/main/tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 14.4MB/s]\u001b[0m\n",
      "\u001b[34mThe following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: str_labels, text. If str_labels, text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\u001b[0m\n",
      "\u001b[34mThe following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: str_labels, text. If str_labels, text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m***** Running training *****\u001b[0m\n",
      "\u001b[34mNum examples = 12797\u001b[0m\n",
      "\u001b[34m***** Running training *****\n",
      "  Num examples = 12797\u001b[0m\n",
      "\u001b[34mNum Epochs = 1\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\u001b[0m\n",
      "\u001b[34mGradient Accumulation steps = 1\n",
      "  Total optimization steps = 400\u001b[0m\n",
      "\u001b[34mNum Epochs = 1\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 400\u001b[0m\n",
      "\u001b[34mNumber of trainable parameters = 66958086\u001b[0m\n",
      "\u001b[34mNumber of trainable parameters = 66958086\u001b[0m\n",
      "\u001b[34m0%|          | 0/400 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[2023-10-25 06:47:53.912: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.26.0 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34m2023-10-25 06:47:53,919 - root - INFO - Using NamedTuple = typing._NamedTuple instead.\u001b[0m\n",
      "\u001b[34m[2023-10-25 06:47:53.955 algo-1:49 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2023-10-25 06:47:53.994 algo-1:49 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2023-10-25 06:47:53.995 algo-1:49 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2023-10-25 06:47:53.995 algo-1:49 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2023-10-25 06:47:53.996 algo-1:49 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2023-10-25 06:47:53.996 algo-1:49 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34mYou're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34mYou're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34m0%|          | 1/400 [00:01<11:09,  1.68s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 2/400 [00:02<06:21,  1.04it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 3/400 [00:02<04:49,  1.37it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 4/400 [00:03<04:05,  1.61it/s]\u001b[0m\n",
      "\u001b[34m1%|▏         | 5/400 [00:03<03:41,  1.78it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 6/400 [00:03<03:26,  1.90it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 7/400 [00:04<03:17,  1.99it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 8/400 [00:04<03:11,  2.04it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 9/400 [00:05<03:07,  2.09it/s]\u001b[0m\n",
      "\u001b[34m2%|▎         | 10/400 [00:05<03:04,  2.12it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 11/400 [00:06<03:02,  2.14it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 12/400 [00:06<03:00,  2.15it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 13/400 [00:07<02:58,  2.17it/s]\u001b[0m\n",
      "\u001b[34m4%|▎         | 14/400 [00:07<02:57,  2.17it/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 15/400 [00:08<02:57,  2.17it/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 16/400 [00:08<02:56,  2.18it/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 17/400 [00:08<02:56,  2.17it/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 18/400 [00:09<02:55,  2.17it/s]\u001b[0m\n",
      "\u001b[34m5%|▍         | 19/400 [00:09<02:55,  2.17it/s]\u001b[0m\n",
      "\u001b[34m5%|▌         | 20/400 [00:10<02:54,  2.18it/s]\u001b[0m\n",
      "\u001b[34m5%|▌         | 21/400 [00:10<02:53,  2.19it/s]\u001b[0m\n",
      "\u001b[34m6%|▌         | 22/400 [00:11<02:52,  2.19it/s]\u001b[0m\n",
      "\u001b[34m6%|▌         | 23/400 [00:11<02:52,  2.19it/s]\u001b[0m\n",
      "\u001b[34m6%|▌         | 24/400 [00:12<02:51,  2.19it/s]\u001b[0m\n",
      "\u001b[34m6%|▋         | 25/400 [00:12<02:51,  2.19it/s]\u001b[0m\n",
      "\u001b[34m6%|▋         | 26/400 [00:13<02:50,  2.19it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 27/400 [00:13<02:50,  2.19it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 28/400 [00:14<02:50,  2.19it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 29/400 [00:14<02:49,  2.19it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 30/400 [00:14<02:48,  2.19it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 31/400 [00:15<02:48,  2.19it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 32/400 [00:15<02:48,  2.19it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 33/400 [00:16<02:47,  2.19it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 34/400 [00:16<02:47,  2.19it/s]\u001b[0m\n",
      "\u001b[34m9%|▉         | 35/400 [00:17<02:46,  2.19it/s]\u001b[0m\n",
      "\u001b[34m9%|▉         | 36/400 [00:17<02:46,  2.19it/s]\u001b[0m\n",
      "\u001b[34m9%|▉         | 37/400 [00:18<02:45,  2.19it/s]\u001b[0m\n",
      "\u001b[34m10%|▉         | 38/400 [00:18<02:45,  2.18it/s]\u001b[0m\n",
      "\u001b[34m10%|▉         | 39/400 [00:19<02:45,  2.18it/s]\u001b[0m\n",
      "\u001b[34m10%|█         | 40/400 [00:19<02:44,  2.18it/s]\u001b[0m\n",
      "\u001b[34m10%|█         | 41/400 [00:19<02:44,  2.19it/s]\u001b[0m\n",
      "\u001b[34m10%|█         | 42/400 [00:20<02:43,  2.19it/s]\u001b[0m\n",
      "\u001b[34m11%|█         | 43/400 [00:20<02:42,  2.19it/s]\u001b[0m\n",
      "\u001b[34m11%|█         | 44/400 [00:21<02:42,  2.19it/s]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 45/400 [00:21<02:42,  2.19it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 46/400 [00:22<02:41,  2.19it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 47/400 [00:22<02:41,  2.19it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 48/400 [00:23<02:40,  2.19it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 49/400 [00:23<02:40,  2.19it/s]\u001b[0m\n",
      "\u001b[34m12%|█▎        | 50/400 [00:24<02:40,  2.18it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 51/400 [00:24<02:40,  2.18it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 52/400 [00:24<02:39,  2.18it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 53/400 [00:25<02:38,  2.19it/s]\u001b[0m\n",
      "\u001b[34m14%|█▎        | 54/400 [00:25<02:38,  2.19it/s]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 55/400 [00:26<02:37,  2.19it/s]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 56/400 [00:26<02:37,  2.18it/s]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 57/400 [00:27<02:36,  2.19it/s]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 58/400 [00:27<02:36,  2.18it/s]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 59/400 [00:28<02:36,  2.18it/s]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 60/400 [00:28<02:35,  2.18it/s]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 61/400 [00:29<02:35,  2.18it/s]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 62/400 [00:29<02:35,  2.18it/s]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 63/400 [00:30<02:34,  2.18it/s]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 64/400 [00:30<02:33,  2.19it/s]\u001b[0m\n",
      "\u001b[34m16%|█▋        | 65/400 [00:30<02:33,  2.19it/s]\u001b[0m\n",
      "\u001b[34m16%|█▋        | 66/400 [00:31<02:33,  2.18it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 67/400 [00:31<02:32,  2.18it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 68/400 [00:32<02:32,  2.17it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 69/400 [00:32<02:31,  2.18it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 70/400 [00:33<02:31,  2.18it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 71/400 [00:33<02:30,  2.18it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 72/400 [00:34<02:30,  2.18it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 73/400 [00:34<02:29,  2.19it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 74/400 [00:35<02:29,  2.19it/s]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 75/400 [00:35<02:28,  2.18it/s]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 76/400 [00:35<02:28,  2.18it/s]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 77/400 [00:36<02:27,  2.18it/s]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 78/400 [00:36<02:27,  2.18it/s]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 79/400 [00:37<02:27,  2.18it/s]\u001b[0m\n",
      "\u001b[34m20%|██        | 80/400 [00:37<02:26,  2.18it/s]\u001b[0m\n",
      "\u001b[34m20%|██        | 81/400 [00:38<02:26,  2.18it/s]\u001b[0m\n",
      "\u001b[34m20%|██        | 82/400 [00:38<02:25,  2.19it/s]\u001b[0m\n",
      "\u001b[34m21%|██        | 83/400 [00:39<02:24,  2.19it/s]\u001b[0m\n",
      "\u001b[34m21%|██        | 84/400 [00:39<02:24,  2.19it/s]\u001b[0m\n",
      "\u001b[34m21%|██▏       | 85/400 [00:40<02:23,  2.19it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 86/400 [00:40<02:23,  2.19it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 87/400 [00:41<02:23,  2.19it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 88/400 [00:41<02:23,  2.18it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 89/400 [00:41<02:23,  2.17it/s]\u001b[0m\n",
      "\u001b[34m22%|██▎       | 90/400 [00:42<02:22,  2.18it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 91/400 [00:42<02:21,  2.18it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 92/400 [00:43<02:21,  2.18it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 93/400 [00:43<02:20,  2.18it/s]\u001b[0m\n",
      "\u001b[34m24%|██▎       | 94/400 [00:44<02:20,  2.18it/s]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 95/400 [00:44<02:19,  2.18it/s]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 96/400 [00:45<02:19,  2.18it/s]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 97/400 [00:45<02:19,  2.18it/s]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 98/400 [00:46<02:19,  2.17it/s]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 99/400 [00:46<02:18,  2.17it/s]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 100/400 [00:47<02:18,  2.17it/s]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 101/400 [00:47<02:17,  2.17it/s]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 102/400 [00:47<02:17,  2.17it/s]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 103/400 [00:48<02:16,  2.18it/s]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 104/400 [00:48<02:16,  2.17it/s]\u001b[0m\n",
      "\u001b[34m26%|██▋       | 105/400 [00:49<02:15,  2.18it/s]\u001b[0m\n",
      "\u001b[34m26%|██▋       | 106/400 [00:49<02:14,  2.18it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 107/400 [00:50<02:14,  2.18it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 108/400 [00:50<02:13,  2.18it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 109/400 [00:51<02:13,  2.19it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 110/400 [00:51<02:12,  2.19it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 111/400 [00:52<02:12,  2.18it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 112/400 [00:52<02:12,  2.18it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 113/400 [00:52<02:11,  2.18it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 114/400 [00:53<02:11,  2.18it/s]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 115/400 [00:53<02:10,  2.18it/s]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 116/400 [00:54<02:10,  2.18it/s]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 117/400 [00:54<02:09,  2.18it/s]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 118/400 [00:55<02:09,  2.18it/s]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 119/400 [00:55<02:08,  2.18it/s]\u001b[0m\n",
      "\u001b[34m30%|███       | 120/400 [00:56<02:08,  2.18it/s]\u001b[0m\n",
      "\u001b[34m30%|███       | 121/400 [00:56<02:07,  2.18it/s]\u001b[0m\n",
      "\u001b[34m30%|███       | 122/400 [00:57<02:07,  2.18it/s]\u001b[0m\n",
      "\u001b[34m31%|███       | 123/400 [00:57<02:06,  2.18it/s]\u001b[0m\n",
      "\u001b[34m31%|███       | 124/400 [00:58<02:06,  2.18it/s]\u001b[0m\n",
      "\u001b[34m31%|███▏      | 125/400 [00:58<02:05,  2.19it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 126/400 [00:58<02:05,  2.19it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 127/400 [00:59<02:05,  2.18it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 128/400 [00:59<02:04,  2.18it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 129/400 [01:00<02:04,  2.18it/s]\u001b[0m\n",
      "\u001b[34m32%|███▎      | 130/400 [01:00<02:03,  2.18it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 131/400 [01:01<02:03,  2.18it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 132/400 [01:01<02:02,  2.19it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 133/400 [01:02<02:02,  2.19it/s]\u001b[0m\n",
      "\u001b[34m34%|███▎      | 134/400 [01:02<02:01,  2.19it/s]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 135/400 [01:03<02:01,  2.18it/s]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 136/400 [01:03<02:01,  2.18it/s]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 137/400 [01:03<02:01,  2.17it/s]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 138/400 [01:04<02:00,  2.17it/s]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 139/400 [01:04<01:59,  2.18it/s]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 140/400 [01:05<01:59,  2.18it/s]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 141/400 [01:05<01:58,  2.18it/s]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 142/400 [01:06<01:58,  2.18it/s]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 143/400 [01:06<01:57,  2.18it/s]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 144/400 [01:07<01:57,  2.19it/s]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 145/400 [01:07<01:56,  2.19it/s]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 146/400 [01:08<01:56,  2.18it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 147/400 [01:08<01:55,  2.18it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 148/400 [01:09<01:55,  2.18it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 149/400 [01:09<01:55,  2.18it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 150/400 [01:09<01:54,  2.18it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 151/400 [01:10<01:54,  2.18it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 152/400 [01:10<01:53,  2.18it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 153/400 [01:11<01:52,  2.19it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 154/400 [01:11<01:52,  2.18it/s]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 155/400 [01:12<01:52,  2.18it/s]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 156/400 [01:12<01:52,  2.18it/s]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 157/400 [01:13<01:51,  2.17it/s]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 158/400 [01:13<01:51,  2.18it/s]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 159/400 [01:14<01:50,  2.17it/s]\u001b[0m\n",
      "\u001b[34m40%|████      | 160/400 [01:14<01:50,  2.17it/s]\u001b[0m\n",
      "\u001b[34m40%|████      | 161/400 [01:14<01:49,  2.17it/s]\u001b[0m\n",
      "\u001b[34m40%|████      | 162/400 [01:15<01:49,  2.18it/s]\u001b[0m\n",
      "\u001b[34m41%|████      | 163/400 [01:15<01:49,  2.17it/s]\u001b[0m\n",
      "\u001b[34m41%|████      | 164/400 [01:16<01:48,  2.18it/s]\u001b[0m\n",
      "\u001b[34m41%|████▏     | 165/400 [01:16<01:47,  2.18it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 166/400 [01:17<01:47,  2.17it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 167/400 [01:17<01:47,  2.18it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 168/400 [01:18<01:46,  2.18it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 169/400 [01:18<01:45,  2.18it/s]\u001b[0m\n",
      "\u001b[34m42%|████▎     | 170/400 [01:19<01:45,  2.18it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 171/400 [01:19<01:45,  2.18it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 172/400 [01:20<01:44,  2.18it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 173/400 [01:20<01:44,  2.18it/s]\u001b[0m\n",
      "\u001b[34m44%|████▎     | 174/400 [01:20<01:43,  2.18it/s]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 175/400 [01:21<01:43,  2.17it/s]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 176/400 [01:21<01:43,  2.17it/s]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 177/400 [01:22<01:42,  2.18it/s]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 178/400 [01:22<01:41,  2.18it/s]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 179/400 [01:23<01:41,  2.18it/s]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 180/400 [01:23<01:40,  2.19it/s]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 181/400 [01:24<01:40,  2.19it/s]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 182/400 [01:24<01:40,  2.18it/s]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 183/400 [01:25<01:39,  2.18it/s]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 184/400 [01:25<01:38,  2.19it/s]\u001b[0m\n",
      "\u001b[34m46%|████▋     | 185/400 [01:25<01:38,  2.19it/s]\u001b[0m\n",
      "\u001b[34m46%|████▋     | 186/400 [01:26<01:37,  2.19it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 187/400 [01:26<01:37,  2.19it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 188/400 [01:27<01:36,  2.19it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 189/400 [01:27<01:36,  2.19it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 190/400 [01:28<01:36,  2.18it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 191/400 [01:28<01:35,  2.18it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 192/400 [01:29<01:35,  2.18it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 193/400 [01:29<01:34,  2.19it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 194/400 [01:30<01:34,  2.19it/s]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 195/400 [01:30<01:33,  2.18it/s]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 196/400 [01:31<01:33,  2.18it/s]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 197/400 [01:31<01:33,  2.18it/s]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 198/400 [01:31<01:32,  2.18it/s]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 199/400 [01:32<01:32,  2.18it/s]\u001b[0m\n",
      "\u001b[34m50%|█████     | 200/400 [01:32<01:31,  2.18it/s]\u001b[0m\n",
      "\u001b[34m50%|█████     | 201/400 [01:33<01:31,  2.18it/s]\u001b[0m\n",
      "\u001b[34m50%|█████     | 202/400 [01:33<01:30,  2.18it/s]\u001b[0m\n",
      "\u001b[34m51%|█████     | 203/400 [01:34<01:30,  2.19it/s]\u001b[0m\n",
      "\u001b[34m51%|█████     | 204/400 [01:34<01:29,  2.18it/s]\u001b[0m\n",
      "\u001b[34m51%|█████▏    | 205/400 [01:35<01:29,  2.18it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 206/400 [01:35<01:29,  2.18it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 207/400 [01:36<01:28,  2.18it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 208/400 [01:36<01:27,  2.18it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 209/400 [01:36<01:27,  2.19it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▎    | 210/400 [01:37<01:26,  2.19it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 211/400 [01:37<01:26,  2.19it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 212/400 [01:38<01:25,  2.19it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 213/400 [01:38<01:25,  2.19it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 214/400 [01:39<01:25,  2.18it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 215/400 [01:39<01:24,  2.18it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 216/400 [01:40<01:24,  2.18it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 217/400 [01:40<01:23,  2.19it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 218/400 [01:41<01:23,  2.19it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 219/400 [01:41<01:22,  2.18it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 220/400 [01:42<01:22,  2.18it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 221/400 [01:42<01:21,  2.18it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 222/400 [01:42<01:21,  2.18it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 223/400 [01:43<01:21,  2.18it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 224/400 [01:43<01:21,  2.17it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 225/400 [01:44<01:20,  2.17it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 226/400 [01:44<01:20,  2.17it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 227/400 [01:45<01:19,  2.17it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 228/400 [01:45<01:19,  2.18it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 229/400 [01:46<01:18,  2.18it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▊    | 230/400 [01:46<01:17,  2.18it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 231/400 [01:47<01:17,  2.18it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 232/400 [01:47<01:17,  2.18it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 233/400 [01:47<01:16,  2.18it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 234/400 [01:48<01:16,  2.17it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 235/400 [01:48<01:16,  2.17it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 236/400 [01:49<01:15,  2.17it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 237/400 [01:49<01:15,  2.17it/s]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 238/400 [01:50<01:14,  2.18it/s]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 239/400 [01:50<01:13,  2.18it/s]\u001b[0m\n",
      "\u001b[34m60%|██████    | 240/400 [01:51<01:13,  2.17it/s]\u001b[0m\n",
      "\u001b[34m60%|██████    | 241/400 [01:51<01:13,  2.17it/s]\u001b[0m\n",
      "\u001b[34m60%|██████    | 242/400 [01:52<01:12,  2.17it/s]\u001b[0m\n",
      "\u001b[34m61%|██████    | 243/400 [01:52<01:12,  2.17it/s]\u001b[0m\n",
      "\u001b[34m61%|██████    | 244/400 [01:53<01:11,  2.17it/s]\u001b[0m\n",
      "\u001b[34m61%|██████▏   | 245/400 [01:53<01:11,  2.17it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 246/400 [01:53<01:10,  2.18it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 247/400 [01:54<01:10,  2.18it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 248/400 [01:54<01:09,  2.18it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 249/400 [01:55<01:09,  2.18it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▎   | 250/400 [01:55<01:08,  2.18it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 251/400 [01:56<01:08,  2.18it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 252/400 [01:56<01:07,  2.18it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 253/400 [01:57<01:07,  2.18it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 254/400 [01:57<01:06,  2.18it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 255/400 [01:58<01:06,  2.18it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 256/400 [01:58<01:06,  2.18it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 257/400 [01:59<01:05,  2.18it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 258/400 [01:59<01:05,  2.18it/s]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 259/400 [01:59<01:04,  2.19it/s]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 260/400 [02:00<01:04,  2.19it/s]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 261/400 [02:00<01:03,  2.18it/s]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 262/400 [02:01<01:03,  2.19it/s]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 263/400 [02:01<01:02,  2.19it/s]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 264/400 [02:02<01:02,  2.19it/s]\u001b[0m\n",
      "\u001b[34m66%|██████▋   | 265/400 [02:02<01:01,  2.19it/s]\u001b[0m\n",
      "\u001b[34m66%|██████▋   | 266/400 [02:03<01:01,  2.18it/s]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 267/400 [02:03<01:00,  2.18it/s]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 268/400 [02:04<01:00,  2.18it/s]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 269/400 [02:04<01:00,  2.17it/s]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 270/400 [02:04<00:59,  2.18it/s]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 271/400 [02:05<00:59,  2.18it/s]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 272/400 [02:05<00:58,  2.18it/s]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 273/400 [02:06<00:58,  2.18it/s]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 274/400 [02:06<00:57,  2.18it/s]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 275/400 [02:07<00:57,  2.17it/s]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 276/400 [02:07<00:57,  2.17it/s]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 277/400 [02:08<00:56,  2.16it/s]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 278/400 [02:08<00:56,  2.17it/s]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 279/400 [02:09<00:55,  2.17it/s]\u001b[0m\n",
      "\u001b[34m70%|███████   | 280/400 [02:09<00:55,  2.17it/s]\u001b[0m\n",
      "\u001b[34m70%|███████   | 281/400 [02:10<00:55,  2.16it/s]\u001b[0m\n",
      "\u001b[34m70%|███████   | 282/400 [02:10<00:54,  2.17it/s]\u001b[0m\n",
      "\u001b[34m71%|███████   | 283/400 [02:10<00:54,  2.17it/s]\u001b[0m\n",
      "\u001b[34m71%|███████   | 284/400 [02:11<00:53,  2.17it/s]\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 285/400 [02:11<00:52,  2.17it/s]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 286/400 [02:12<00:52,  2.17it/s]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 287/400 [02:12<00:52,  2.17it/s]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 288/400 [02:13<00:51,  2.17it/s]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 289/400 [02:13<00:51,  2.17it/s]\u001b[0m\n",
      "\u001b[34m72%|███████▎  | 290/400 [02:14<00:50,  2.18it/s]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 291/400 [02:14<00:50,  2.17it/s]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 292/400 [02:15<00:49,  2.17it/s]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 293/400 [02:15<00:49,  2.17it/s]\u001b[0m\n",
      "\u001b[34m74%|███████▎  | 294/400 [02:16<00:48,  2.18it/s]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 295/400 [02:16<00:48,  2.18it/s]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 296/400 [02:16<00:47,  2.18it/s]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 297/400 [02:17<00:47,  2.18it/s]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 298/400 [02:17<00:46,  2.18it/s]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 299/400 [02:18<00:46,  2.18it/s]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 300/400 [02:18<00:45,  2.18it/s]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 301/400 [02:19<00:45,  2.18it/s]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 302/400 [02:19<00:44,  2.18it/s]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 303/400 [02:20<00:44,  2.18it/s]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 304/400 [02:20<00:44,  2.18it/s]\u001b[0m\n",
      "\u001b[34m76%|███████▋  | 305/400 [02:21<00:43,  2.18it/s]\u001b[0m\n",
      "\u001b[34m76%|███████▋  | 306/400 [02:21<00:43,  2.18it/s]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 307/400 [02:21<00:42,  2.18it/s]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 308/400 [02:22<00:42,  2.18it/s]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 309/400 [02:22<00:41,  2.18it/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 310/400 [02:23<00:41,  2.18it/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 311/400 [02:23<00:40,  2.18it/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 312/400 [02:24<00:40,  2.18it/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 313/400 [02:24<00:40,  2.17it/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 314/400 [02:25<00:39,  2.17it/s]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 315/400 [02:25<00:39,  2.17it/s]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 316/400 [02:26<00:38,  2.17it/s]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 317/400 [02:26<00:38,  2.17it/s]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 318/400 [02:27<00:37,  2.18it/s]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 319/400 [02:27<00:37,  2.18it/s]\u001b[0m\n",
      "\u001b[34m80%|████████  | 320/400 [02:27<00:36,  2.18it/s]\u001b[0m\n",
      "\u001b[34m80%|████████  | 321/400 [02:28<00:36,  2.17it/s]\u001b[0m\n",
      "\u001b[34m80%|████████  | 322/400 [02:28<00:36,  2.17it/s]\u001b[0m\n",
      "\u001b[34m81%|████████  | 323/400 [02:29<00:35,  2.17it/s]\u001b[0m\n",
      "\u001b[34m81%|████████  | 324/400 [02:29<00:35,  2.17it/s]\u001b[0m\n",
      "\u001b[34m81%|████████▏ | 325/400 [02:30<00:34,  2.17it/s]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 326/400 [02:30<00:34,  2.17it/s]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 327/400 [02:31<00:33,  2.17it/s]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 328/400 [02:31<00:33,  2.17it/s]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 329/400 [02:32<00:32,  2.17it/s]\u001b[0m\n",
      "\u001b[34m82%|████████▎ | 330/400 [02:32<00:32,  2.17it/s]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 331/400 [02:33<00:31,  2.17it/s]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 332/400 [02:33<00:31,  2.17it/s]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 333/400 [02:33<00:30,  2.17it/s]\u001b[0m\n",
      "\u001b[34m84%|████████▎ | 334/400 [02:34<00:30,  2.17it/s]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 335/400 [02:34<00:29,  2.17it/s]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 336/400 [02:35<00:29,  2.18it/s]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 337/400 [02:35<00:28,  2.18it/s]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 338/400 [02:36<00:28,  2.18it/s]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 339/400 [02:36<00:27,  2.18it/s]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 340/400 [02:37<00:27,  2.18it/s]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 341/400 [02:37<00:27,  2.18it/s]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 342/400 [02:38<00:26,  2.18it/s]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 343/400 [02:38<00:26,  2.18it/s]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 344/400 [02:39<00:25,  2.18it/s]\u001b[0m\n",
      "\u001b[34m86%|████████▋ | 345/400 [02:39<00:25,  2.18it/s]\u001b[0m\n",
      "\u001b[34m86%|████████▋ | 346/400 [02:39<00:24,  2.17it/s]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 347/400 [02:40<00:24,  2.17it/s]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 348/400 [02:40<00:23,  2.17it/s]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 349/400 [02:41<00:23,  2.17it/s]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 350/400 [02:41<00:23,  2.17it/s]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 351/400 [02:42<00:22,  2.17it/s]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 352/400 [02:42<00:22,  2.17it/s]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 353/400 [02:43<00:21,  2.17it/s]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 354/400 [02:43<00:21,  2.17it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 355/400 [02:44<00:20,  2.17it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 356/400 [02:44<00:20,  2.17it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 357/400 [02:44<00:19,  2.17it/s]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 358/400 [02:45<00:19,  2.17it/s]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 359/400 [02:45<00:18,  2.17it/s]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 360/400 [02:46<00:18,  2.18it/s]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 361/400 [02:46<00:17,  2.18it/s]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 362/400 [02:47<00:17,  2.18it/s]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 363/400 [02:47<00:17,  2.17it/s]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 364/400 [02:48<00:16,  2.18it/s]\u001b[0m\n",
      "\u001b[34m91%|█████████▏| 365/400 [02:48<00:16,  2.17it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 366/400 [02:49<00:15,  2.17it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 367/400 [02:49<00:15,  2.17it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 368/400 [02:50<00:14,  2.17it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 369/400 [02:50<00:14,  2.17it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▎| 370/400 [02:50<00:13,  2.17it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 371/400 [02:51<00:13,  2.18it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 372/400 [02:51<00:12,  2.18it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 373/400 [02:52<00:12,  2.18it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▎| 374/400 [02:52<00:11,  2.18it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 375/400 [02:53<00:11,  2.18it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 376/400 [02:53<00:10,  2.18it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 377/400 [02:54<00:10,  2.18it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 378/400 [02:54<00:10,  2.18it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 379/400 [02:55<00:09,  2.18it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 380/400 [02:55<00:09,  2.18it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 381/400 [02:56<00:08,  2.18it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 382/400 [02:56<00:08,  2.17it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 383/400 [02:56<00:07,  2.17it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 384/400 [02:57<00:07,  2.17it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 385/400 [02:57<00:06,  2.17it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 386/400 [02:58<00:06,  2.18it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 387/400 [02:58<00:05,  2.18it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 388/400 [02:59<00:05,  2.18it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 389/400 [02:59<00:05,  2.18it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 390/400 [03:00<00:04,  2.18it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 391/400 [03:00<00:04,  2.18it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 392/400 [03:01<00:03,  2.18it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 393/400 [03:01<00:03,  2.18it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 394/400 [03:01<00:02,  2.18it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 395/400 [03:02<00:02,  2.18it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 396/400 [03:02<00:01,  2.18it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 397/400 [03:03<00:01,  2.17it/s]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 398/400 [03:03<00:00,  2.18it/s]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 399/400 [03:04<00:00,  2.18it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 400/400 [03:04<00:00,  2.23it/s]\u001b[0m\n",
      "\u001b[34mThe following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: str_labels, text. If str_labels, text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\u001b[0m\n",
      "\u001b[34mThe following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: str_labels, text. If str_labels, text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34mNum examples = 3200\n",
      "  Batch size = 64\u001b[0m\n",
      "\u001b[34mNum examples = 3200\n",
      "  Batch size = 64\u001b[0m\n",
      "\u001b[34m0%|          | 0/50 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m4%|▍         | 2/50 [00:00<00:07,  6.41it/s]#033[A\u001b[0m\n",
      "\u001b[34m6%|▌         | 3/50 [00:00<00:10,  4.51it/s]#033[A\u001b[0m\n",
      "\u001b[34m8%|▊         | 4/50 [00:00<00:11,  3.92it/s]#033[A\u001b[0m\n",
      "\u001b[34m10%|█         | 5/50 [00:01<00:12,  3.64it/s]#033[A\u001b[0m\n",
      "\u001b[34m12%|█▏        | 6/50 [00:01<00:12,  3.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m14%|█▍        | 7/50 [00:01<00:12,  3.38it/s]#033[A\u001b[0m\n",
      "\u001b[34m16%|█▌        | 8/50 [00:02<00:12,  3.33it/s]#033[A\u001b[0m\n",
      "\u001b[34m18%|█▊        | 9/50 [00:02<00:12,  3.29it/s]#033[A\u001b[0m\n",
      "\u001b[34m20%|██        | 10/50 [00:02<00:12,  3.25it/s]#033[A\u001b[0m\n",
      "\u001b[34m22%|██▏       | 11/50 [00:03<00:12,  3.23it/s]#033[A\u001b[0m\n",
      "\u001b[34m24%|██▍       | 12/50 [00:03<00:11,  3.20it/s]#033[A\u001b[0m\n",
      "\u001b[34m26%|██▌       | 13/50 [00:03<00:11,  3.19it/s]#033[A\u001b[0m\n",
      "\u001b[34m28%|██▊       | 14/50 [00:04<00:11,  3.19it/s]#033[A\u001b[0m\n",
      "\u001b[34m30%|███       | 15/50 [00:04<00:11,  3.18it/s]#033[A\u001b[0m\n",
      "\u001b[34m32%|███▏      | 16/50 [00:04<00:10,  3.17it/s]#033[A\u001b[0m\n",
      "\u001b[34m34%|███▍      | 17/50 [00:05<00:10,  3.18it/s]#033[A\u001b[0m\n",
      "\u001b[34m36%|███▌      | 18/50 [00:05<00:10,  3.19it/s]#033[A\u001b[0m\n",
      "\u001b[34m38%|███▊      | 19/50 [00:05<00:09,  3.20it/s]#033[A\u001b[0m\n",
      "\u001b[34m40%|████      | 20/50 [00:05<00:09,  3.21it/s]#033[A\u001b[0m\n",
      "\u001b[34m42%|████▏     | 21/50 [00:06<00:09,  3.21it/s]#033[A\u001b[0m\n",
      "\u001b[34m44%|████▍     | 22/50 [00:06<00:08,  3.21it/s]#033[A\u001b[0m\n",
      "\u001b[34m46%|████▌     | 23/50 [00:06<00:08,  3.21it/s]#033[A\u001b[0m\n",
      "\u001b[34m48%|████▊     | 24/50 [00:07<00:08,  3.21it/s]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 25/50 [00:07<00:07,  3.21it/s]#033[A\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 26/50 [00:07<00:07,  3.21it/s]#033[A\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 27/50 [00:08<00:07,  3.21it/s]#033[A\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 28/50 [00:08<00:06,  3.21it/s]#033[A\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 29/50 [00:08<00:06,  3.20it/s]#033[A\u001b[0m\n",
      "\u001b[34m60%|██████    | 30/50 [00:09<00:06,  3.21it/s]#033[A\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 31/50 [00:09<00:05,  3.20it/s]#033[A\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 32/50 [00:09<00:05,  3.21it/s]#033[A\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 33/50 [00:10<00:05,  3.21it/s]#033[A\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 34/50 [00:10<00:04,  3.21it/s]#033[A\u001b[0m\n",
      "\u001b[34m70%|███████   | 35/50 [00:10<00:04,  3.21it/s]#033[A\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 36/50 [00:10<00:04,  3.21it/s]#033[A\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 37/50 [00:11<00:04,  3.21it/s]#033[A\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 38/50 [00:11<00:03,  3.21it/s]#033[A\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 39/50 [00:11<00:03,  3.21it/s]#033[A\u001b[0m\n",
      "\u001b[34m80%|████████  | 40/50 [00:12<00:03,  3.21it/s]#033[A\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 41/50 [00:12<00:02,  3.21it/s]#033[A\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 42/50 [00:12<00:02,  3.20it/s]#033[A\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 43/50 [00:13<00:02,  3.19it/s]#033[A\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 44/50 [00:13<00:01,  3.20it/s]#033[A\u001b[0m\n",
      "\u001b[34m90%|█████████ | 45/50 [00:13<00:01,  3.20it/s]#033[A\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 46/50 [00:14<00:01,  3.20it/s]#033[A\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 47/50 [00:14<00:00,  3.20it/s]#033[A\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 48/50 [00:14<00:00,  3.19it/s]#033[A\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 49/50 [00:15<00:00,  3.20it/s]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 50/50 [00:15<00:00,  3.20it/s]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.24509043991565704, 'eval_f1': 0.6472479667108001, 'eval_roc_auc': 0.7555937500000001, 'eval_accuracy': 0.534375, 'eval_runtime': 15.644, 'eval_samples_per_second': 204.551, 'eval_steps_per_second': 3.196, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34m100%|██████████| 400/400 [03:20<00:00,  2.23it/s]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 50/50 [00:15<00:00,  3.20it/s]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mTraining completed. Do not forget to share your model on huggingface.co/models =)\u001b[0m\n",
      "\u001b[34mTraining completed. Do not forget to share your model on huggingface.co/models =)\u001b[0m\n",
      "\u001b[34m100%|██████████| 400/400 [03:20<00:00,  2.23it/s]\u001b[0m\n",
      "\u001b[34m{'train_runtime': 200.3546, 'train_samples_per_second': 63.872, 'train_steps_per_second': 1.996, 'train_loss': 0.3850246047973633, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34m100%|██████████| 400/400 [03:20<00:00,  2.00it/s]\u001b[0m\n",
      "\u001b[34mThe following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: str_labels, text. If str_labels, text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\u001b[0m\n",
      "\u001b[34mThe following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: str_labels, text. If str_labels, text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34mNum examples = 3200\n",
      "  Batch size = 64\u001b[0m\n",
      "\u001b[34mNum examples = 3200\n",
      "  Batch size = 64\u001b[0m\n",
      "\u001b[34m0%|          | 0/50 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 2/50 [00:00<00:07,  6.44it/s]\u001b[0m\n",
      "\u001b[34m6%|▌         | 3/50 [00:00<00:10,  4.54it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 4/50 [00:00<00:11,  3.93it/s]\u001b[0m\n",
      "\u001b[34m10%|█         | 5/50 [00:01<00:12,  3.65it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 6/50 [00:01<00:12,  3.49it/s]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 7/50 [00:01<00:12,  3.39it/s]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 8/50 [00:02<00:12,  3.32it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 9/50 [00:02<00:12,  3.28it/s]\u001b[0m\n",
      "\u001b[34m20%|██        | 10/50 [00:02<00:12,  3.27it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 11/50 [00:03<00:12,  3.25it/s]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 12/50 [00:03<00:11,  3.24it/s]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 13/50 [00:03<00:11,  3.23it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 14/50 [00:04<00:11,  3.23it/s]\u001b[0m\n",
      "\u001b[34m30%|███       | 15/50 [00:04<00:10,  3.22it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 16/50 [00:04<00:10,  3.22it/s]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 17/50 [00:04<00:10,  3.22it/s]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 18/50 [00:05<00:09,  3.22it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 19/50 [00:05<00:09,  3.21it/s]\u001b[0m\n",
      "\u001b[34m40%|████      | 20/50 [00:05<00:09,  3.22it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 21/50 [00:06<00:09,  3.21it/s]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 22/50 [00:06<00:08,  3.22it/s]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 23/50 [00:06<00:08,  3.21it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 24/50 [00:07<00:08,  3.21it/s]\u001b[0m\n",
      "\u001b[34m50%|█████     | 25/50 [00:07<00:07,  3.21it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 26/50 [00:07<00:07,  3.22it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 27/50 [00:08<00:07,  3.21it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 28/50 [00:08<00:06,  3.21it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 29/50 [00:08<00:06,  3.21it/s]\u001b[0m\n",
      "\u001b[34m60%|██████    | 30/50 [00:09<00:06,  3.21it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 31/50 [00:09<00:05,  3.21it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 32/50 [00:09<00:05,  3.21it/s]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 33/50 [00:09<00:05,  3.21it/s]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 34/50 [00:10<00:04,  3.20it/s]\u001b[0m\n",
      "\u001b[34m70%|███████   | 35/50 [00:10<00:04,  3.21it/s]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 36/50 [00:10<00:04,  3.21it/s]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 37/50 [00:11<00:04,  3.21it/s]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 38/50 [00:11<00:03,  3.21it/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 39/50 [00:11<00:03,  3.20it/s]\u001b[0m\n",
      "\u001b[34m80%|████████  | 40/50 [00:12<00:03,  3.20it/s]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 41/50 [00:12<00:02,  3.20it/s]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 42/50 [00:12<00:02,  3.20it/s]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 43/50 [00:13<00:02,  3.20it/s]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 44/50 [00:13<00:01,  3.20it/s]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 45/50 [00:13<00:01,  3.20it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 46/50 [00:14<00:01,  3.20it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 47/50 [00:14<00:00,  3.20it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 48/50 [00:14<00:00,  3.21it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 49/50 [00:14<00:00,  3.21it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 50/50 [00:15<00:00,  3.20it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 50/50 [00:15<00:00,  3.27it/s]\u001b[0m\n",
      "\u001b[34m***** Eval results *****\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/config.json\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /opt/ml/model/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /opt/ml/model/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /opt/ml/model/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /opt/ml/model/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m2023-10-25 06:51:30,832 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-10-25 06:51:30,833 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-10-25 06:51:30,833 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# access the logs of the training job\n",
    "huggingface_estimator.sagemaker_session.logs_for_job(huggingface_estimator.latest_training_job.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attach to old training job to an estimator \n",
    "\n",
    "In Sagemaker you can attach an old training job to an estimator to continue training, get results etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "# job which is going to be attached to the estimator\n",
    "old_training_job_name=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attach old training job\n",
    "huggingface_estimator_loaded = Estimator.attach(old_training_job_name)\n",
    "\n",
    "# get model output s3 from training job\n",
    "huggingface_estimator_loaded.model_data"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.g4dn.xlarge",
  "interpreter": {
   "hash": "c281c456f1b8161c8906f4af2c08ed2c40c50136979eaae69688b01f70e9f4a9"
  },
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.13 Python 3.9 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/pytorch-1.13-gpu-py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
